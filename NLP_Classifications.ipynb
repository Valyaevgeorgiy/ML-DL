{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XtFQP3RNll3c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re, string, nltk, torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7026,
     "status": "ok",
     "timestamp": 1618423490594,
     "user": {
      "displayName": "Никита Блохин",
      "photoUrl": "",
      "userId": "16402972581398673009"
     },
     "user_tz": -180
    },
    "id": "443CZCLp0_sE",
    "outputId": "ddda53b2-a593-4d13-ee48-cfed23e613b1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jqDHq_AEjRZ1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Представление и предобработка текстовых данных "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vaki7efDpmXo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1.1 Операции по предобработке:\n",
    "* токенизация\n",
    "* стемминг / лемматизация\n",
    "* удаление стоп-слов\n",
    "* удаление пунктуации\n",
    "* приведение к нижнему регистру\n",
    "* любые другие операции над текстом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lMMzGhq0ikz1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text = 'Select your preferences and run the install command. Stable represents the most currently tested and supported version of PyTorch. Note that LibTorch is only available for C++'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Select', 'your', 'preferences', 'and', 'run', 'the', 'install', 'command', '.', 'Stable', 'represents', 'the', 'most', 'currently', 'tested', 'and', 'supported', 'version', 'of', 'PyTorch', '.', 'Note', 'that', 'LibTorch', 'is', 'only', 'available', 'for', 'C++']\n"
     ]
    }
   ],
   "source": [
    "# применяем токенизацию\n",
    "tokens = nltk.tokenize.word_tokenize(text)\n",
    "\n",
    "# выводим результат\n",
    "print(tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* стемминг / лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['play', 'play', 'play', 'player', 'collect']\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "words = [\"playing\", \"played\", \"plays\", \"players\", \"collections\"]\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "print(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сегодня я суметь сделать один из самый важный дело весь мой жизнь — найти тот самую, именно ту, да...\n"
     ]
    }
   ],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "# пример лемматизации предложения\n",
    "sentence = \"Сегодня я сумел сделать одно из самых важных дел всей моей жизни — найти ту самую, именно ту, да...\"\n",
    "lemmas = []\n",
    "\n",
    "for word in sentence.split():\n",
    "    parsed_word = morph.parse(word)[0]\n",
    "    lemmas.append(parsed_word.normal_form)\n",
    "lemmatized_sentence = ' '.join(lemmas)\n",
    "\n",
    "print(lemmatized_sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* удаление стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hadn', 'from', 'over', 'needn', 'her', 'hasn', 'again', 'had', 'myself', 'but', 'whom', 'was', 'do', 'this', 'have', 'mightn', 'why', \"hadn't\", 'no', 'more', 'up', 'me', 'very', 'has', 'mustn', 'once', \"you'd\", 'himself', 're', 'his', 'few', 'because', 'on', 'to', 'were', \"shan't\", 'such', \"hasn't\", 'below', \"haven't\", \"didn't\", 'now', \"that'll\", 'ourselves', 'into', 'there', 'about', 'doesn', 'isn', \"you'll\", \"don't\", 'didn', 'other', \"wasn't\", 'herself', 'most', 'with', 'my', \"mustn't\", 'each', 'same', 'under', 'shouldn', 't', \"you're\", 'their', 'or', 'then', 'own', 'while', 'did', 'in', 'by', \"doesn't\", 'been', 'our', 'yours', 'for', 'doing', 'against', 'don', 'm', \"needn't\", 'having', 'which', 'she', 'who', 'some', 'until', 'above', 'its', 'just', \"wouldn't\", 'further', 'at', 'o', 'am', 'we', 'him', 'being', \"mightn't\", 'weren', 'an', 'before', 'off', 'than', 'won', 'is', 'both', \"aren't\", 'any', 'shan', 'can', \"shouldn't\", 'and', 'between', 'not', 'theirs', 'of', 'out', 'be', 'does', 'as', \"weren't\", 'the', 'aren', 'wouldn', \"couldn't\", 'only', 'haven', 'ours', \"isn't\", 'so', 'ma', 'here', 'yourself', 'themselves', 'down', 'd', 'y', 'll', 'too', 'through', 'hers', 'where', 'i', \"won't\", 'it', \"she's\", 's', 'wasn', 'that', 'couldn', 'a', 'you', \"you've\", 'them', 'are', 'these', 'after', 'during', 'when', 'those', 'he', 'how', \"should've\", \"it's\", 've', 'all', 'will', 'yourselves', 'what', 'should', 'if', 'nor', 'they', 'itself', 'ain', 'your'}\n",
      "\n",
      "This example sentence demonstrate stop word removal.\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words, end=\"\\n\\n\")\n",
    "\n",
    "text = \"This is an example sentence to demonstrate stop word removal.\"\n",
    "tokens = text.split()\n",
    "\n",
    "filtered_tokens = [token for token in tokens if not token in stop_words]\n",
    "filtered_text = \" \".join(filtered_tokens)\n",
    "\n",
    "print(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'а',\n",
       " 'без',\n",
       " 'более',\n",
       " 'больше',\n",
       " 'будет',\n",
       " 'будто',\n",
       " 'бы',\n",
       " 'был',\n",
       " 'была',\n",
       " 'были',\n",
       " 'было',\n",
       " 'быть',\n",
       " 'в',\n",
       " 'вам',\n",
       " 'вас',\n",
       " 'вдруг',\n",
       " 'ведь',\n",
       " 'во',\n",
       " 'вот',\n",
       " 'впрочем',\n",
       " 'все',\n",
       " 'всегда',\n",
       " 'всего',\n",
       " 'всех',\n",
       " 'всю',\n",
       " 'вы',\n",
       " 'где',\n",
       " 'да',\n",
       " 'даже',\n",
       " 'два',\n",
       " 'для',\n",
       " 'до',\n",
       " 'другой',\n",
       " 'его',\n",
       " 'ее',\n",
       " 'ей',\n",
       " 'ему',\n",
       " 'если',\n",
       " 'есть',\n",
       " 'еще',\n",
       " 'ж',\n",
       " 'же',\n",
       " 'за',\n",
       " 'зачем',\n",
       " 'здесь',\n",
       " 'и',\n",
       " 'из',\n",
       " 'или',\n",
       " 'им',\n",
       " 'иногда',\n",
       " 'их',\n",
       " 'к',\n",
       " 'как',\n",
       " 'какая',\n",
       " 'какой',\n",
       " 'когда',\n",
       " 'конечно',\n",
       " 'кто',\n",
       " 'куда',\n",
       " 'ли',\n",
       " 'лучше',\n",
       " 'между',\n",
       " 'меня',\n",
       " 'мне',\n",
       " 'много',\n",
       " 'может',\n",
       " 'можно',\n",
       " 'мой',\n",
       " 'моя',\n",
       " 'мы',\n",
       " 'на',\n",
       " 'над',\n",
       " 'надо',\n",
       " 'наконец',\n",
       " 'нас',\n",
       " 'не',\n",
       " 'него',\n",
       " 'нее',\n",
       " 'ней',\n",
       " 'нельзя',\n",
       " 'нет',\n",
       " 'ни',\n",
       " 'нибудь',\n",
       " 'никогда',\n",
       " 'ним',\n",
       " 'них',\n",
       " 'ничего',\n",
       " 'но',\n",
       " 'ну',\n",
       " 'о',\n",
       " 'об',\n",
       " 'один',\n",
       " 'он',\n",
       " 'она',\n",
       " 'они',\n",
       " 'опять',\n",
       " 'от',\n",
       " 'перед',\n",
       " 'по',\n",
       " 'под',\n",
       " 'после',\n",
       " 'потом',\n",
       " 'потому',\n",
       " 'почти',\n",
       " 'при',\n",
       " 'про',\n",
       " 'раз',\n",
       " 'разве',\n",
       " 'с',\n",
       " 'сам',\n",
       " 'свою',\n",
       " 'себе',\n",
       " 'себя',\n",
       " 'сейчас',\n",
       " 'со',\n",
       " 'совсем',\n",
       " 'так',\n",
       " 'такой',\n",
       " 'там',\n",
       " 'тебя',\n",
       " 'тем',\n",
       " 'теперь',\n",
       " 'то',\n",
       " 'тогда',\n",
       " 'того',\n",
       " 'тоже',\n",
       " 'только',\n",
       " 'том',\n",
       " 'тот',\n",
       " 'три',\n",
       " 'тут',\n",
       " 'ты',\n",
       " 'у',\n",
       " 'уж',\n",
       " 'уже',\n",
       " 'хорошо',\n",
       " 'хоть',\n",
       " 'чего',\n",
       " 'чем',\n",
       " 'через',\n",
       " 'что',\n",
       " 'чтоб',\n",
       " 'чтобы',\n",
       " 'чуть',\n",
       " 'эти',\n",
       " 'этого',\n",
       " 'этой',\n",
       " 'этом',\n",
       " 'этот',\n",
       " 'эту',\n",
       " 'я'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('russian'))\n",
    "stop_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "bUhfertRtXE5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Реализовать функцию `preprocess_text(text: str)`, которая:\n",
    "* приводит строку к нижнему регистру\n",
    "* заменяет все символы, кроме a-z, A-Z и знаков .,!? на пробел\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is an example sentence to demonstrate stop word removal.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text: str) -> str:\n",
    "    return ''.join([' ' if not char.isalpha() and char not in ['?', '!', '.', ','] else char for char in text.lower()])\n",
    "\n",
    "preprocess_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'начинается  новое      приключение   совсем скоро   sap  '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text('Начинается %новое; % **приключение** совсем скоро &&SAP&&')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2Dt1ssIqckC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1.2 Представление текстовых данных при помощи бинарного кодирования\n",
    "\n",
    "\n",
    "Представить первое предложение из `text` в виде тензора `sentence_t`: `sentence_t[i] == 1`, если __слово__ с индексом `i` присуствует в предложении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is an example sentence to demonstrate stop word removal.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_item = preprocess_text(text)\n",
    "processed_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': 0, 'word': 1, 'to': 2, 'This': 3, 'stop': 4, 'example': 5, 'an': 6, 'is': 7, 'removal.': 8, 'demonstrate': 9}\n",
      "This is an example sentence to demonstrate stop word removal.\n",
      "This\n",
      "3\n",
      "is\n",
      "7\n",
      "an\n",
      "6\n",
      "example\n",
      "5\n",
      "sentence\n",
      "0\n",
      "to\n",
      "2\n",
      "demonstrate\n",
      "9\n",
      "stop\n",
      "4\n",
      "word\n",
      "1\n",
      "removal.\n",
      "8\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "first_sentence = sent_tokenize(text)[0]\n",
    "\n",
    "# Создаем словарь слов и присваиваем каждому уникальный индекс\n",
    "dictionary = {word: i for i, word in enumerate(set(text.split()))}\n",
    "print(dictionary)\n",
    "\n",
    "sentence_t = torch.zeros(len(dictionary))\n",
    "\n",
    "print(first_sentence)\n",
    "\n",
    "for word in first_sentence.split():\n",
    "    print(word)\n",
    "    if word in dictionary:\n",
    "        print(dictionary[word])\n",
    "        sentence_t[dictionary[word]] = 1\n",
    "\n",
    "print(sentence_t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "P2Nz_zcgw3N4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Классификация фамилий по национальности\n",
    "\n",
    "Датасет: https://disk.yandex.ru/d/owHew8hzPc7X9Q?w=1\n",
    "\n",
    "2.1 Считать файл `surnames/surnames.csv`.\n",
    "2.2 Закодировать национальности числами, начиная с 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surname</th>\n",
       "      <th>nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Woodford</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coté</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kore</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Koury</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lebzak</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10975</th>\n",
       "      <td>Quraishi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>Innalls</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>Król</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>Purvis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>Messerli</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10980 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        surname  nationality\n",
       "0      Woodford            0\n",
       "1          Coté            1\n",
       "2          Kore            0\n",
       "3         Koury            2\n",
       "4        Lebzak            3\n",
       "...         ...          ...\n",
       "10975  Quraishi            2\n",
       "10976   Innalls            0\n",
       "10977      Król           12\n",
       "10978    Purvis            0\n",
       "10979  Messerli            9\n",
       "\n",
       "[10980 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"./data/surnames.csv\")\n",
    "dataframe['nationality'], _ = pd.factorize(dataframe['nationality'])\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = dataframe['surname'].str.lower()\n",
    "y = dataframe['nationality']\n",
    "n_classes = y.nunique()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2.4 Реализовать класс `Vocab` (токен = __символ__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "kUkSZkDqxNYS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Vocab at 0x2bb586cf520>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, data):\n",
    "        tokens = set()\n",
    "        for item in data:\n",
    "          tokens.update(item)\n",
    "        self.idx_to_token = dict(enumerate(tokens))\n",
    "        self.token_to_idx = {token: idx for idx, token in self.idx_to_token.items()}\n",
    "        self.vocab_len = len(self.idx_to_token)\n",
    "\n",
    "vocab = Vocab(dataframe)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        woodford\n",
       "1            coté\n",
       "2            kore\n",
       "3           koury\n",
       "4          lebzak\n",
       "           ...   \n",
       "10975    quraishi\n",
       "10976     innalls\n",
       "10977        król\n",
       "10978      purvis\n",
       "10979    messerli\n",
       "Name: surname, Length: 10980, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surnames = dataframe[\"surname\"].str.lower()\n",
    "surnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'p', 1: 'w', 2: 'ä', 3: 'm', 4: 'ú', 5: 'à', 6: 'ż', 7: 'ç', 8: 'y', 9: 'ù', 10: 'd', 11: 'o', 12: 'c', 13: 'j', 14: 'í', 15: '1', 16: 'i', 17: 'q', 18: 's', 19: 'ß', 20: 'v', 21: 'u', 22: 'õ', 23: 'è', 24: '-', 25: 'ś', 26: 'ń', 27: 'f', 28: 'ö', 29: 'ą', 30: 'a', 31: 'z', 32: 'á', 33: 'k', 34: 'r', 35: ':', 36: 't', 37: 'x', 38: 'ì', 39: '/', 40: 'b', 41: 'ã', 42: 'g', 43: 'h', 44: 'ñ', 45: 'ò', 46: 'ł', 47: 'é', 48: 'e', 49: 'ó', 50: 'ü', 51: 'n', 52: \"'\", 53: 'l', 54: 'ê'}\n",
      "\n",
      "{'p': 0, 'w': 1, 'ä': 2, 'm': 3, 'ú': 4, 'à': 5, 'ż': 6, 'ç': 7, 'y': 8, 'ù': 9, 'd': 10, 'o': 11, 'c': 12, 'j': 13, 'í': 14, '1': 15, 'i': 16, 'q': 17, 's': 18, 'ß': 19, 'v': 20, 'u': 21, 'õ': 22, 'è': 23, '-': 24, 'ś': 25, 'ń': 26, 'f': 27, 'ö': 28, 'ą': 29, 'a': 30, 'z': 31, 'á': 32, 'k': 33, 'r': 34, ':': 35, 't': 36, 'x': 37, 'ì': 38, '/': 39, 'b': 40, 'ã': 41, 'g': 42, 'h': 43, 'ñ': 44, 'ò': 45, 'ł': 46, 'é': 47, 'e': 48, 'ó': 49, 'ü': 50, 'n': 51, \"'\": 52, 'l': 53, 'ê': 54}\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocab(surnames)\n",
    "print(vocab.idx_to_token, vocab.token_to_idx, sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "10980\n"
     ]
    }
   ],
   "source": [
    "print(vocab.vocab_len)\n",
    "print(len(surnames))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2.5 Реализовать класс `SurnamesDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SurnamesDataset(Dataset):\n",
    "  def __init__(self, X, y, vocab: Vocab):\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "    self.vocab = vocab\n",
    "\n",
    "  def vectorize(self, surname):\n",
    "    '''Генерирует представление фамилии surname в при помощи бинарного кодирования (см. 1.2)'''\n",
    "    surname_t = torch.zeros(self.vocab.vocab_len)\n",
    "    for token in surname:\n",
    "      if surname_t[self.vocab.token_to_idx[token]] == 1:\n",
    "        surname_t[self.vocab.token_to_idx[token]] += 1\n",
    "      else:\n",
    "        surname_t[self.vocab.token_to_idx[token]] = 1\n",
    "    return surname_t\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.vectorize(self.X.iloc[idx]), self.y.iloc[idx]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2.3 Разбить датасет на обучающую и тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = SurnamesDataset(X_train, y_train, vocab)\n",
    "test_dataset = SurnamesDataset(X_test, y_test, vocab)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2.6. Обучить классификатор.\n",
    "2.7 Измерить точность на тестовой выборке. Проверить работоспособность модели: прогнать несколько фамилий студентов группы через модели и проверить результат. Для каждой фамилии выводить 3 наиболее вероятных предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_model(model, train_dataloader, test_dataloader, criterion, optimizer, num_epochs):\n",
    "    model.to(device)\n",
    "    train_losses, test_losses = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss, test_loss = 0, 0\n",
    "        for inputs, labels in train_dataloader:\n",
    "            x = inputs.to(device)\n",
    "            y = labels.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Валидация на val_loader\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        train_losses.append(train_loss/len(train_dataloader))\n",
    "        test_losses.append(test_loss/len(test_dataloader))\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_losses[-1]:.4f}, Test Loss: {test_losses[-1]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for surnames, labels in dataloader:\n",
    "\n",
    "            x = surnames.to(device)\n",
    "            y = labels.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "\n",
    "            correct += (predicted == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, dataset, surname):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        vectorized = dataset.vectorize(surname)\n",
    "        print(vectorized)\n",
    "        tensor = vectorized.unsqueeze(0).to(device)\n",
    "        logits = model(tensor)\n",
    "\n",
    "        probs = torch.softmax(logits, dim=1).squeeze()\n",
    "\n",
    "        top3_probs, top3_indices = torch.topk(probs, k=3)\n",
    "\n",
    "        top3_nationalities = _[top3_indices.detach().cpu().numpy()]\n",
    "        print(f'{surname}: {top3_nationalities.values[0]} ({top3_probs[0].item():.4f}), {top3_nationalities.values[1]} ({top3_probs[1].item():.4f}), {top3_nationalities.values[2]} ({top3_probs[2].item():.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "print(vocab.vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.08607\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(vocab.vocab_len, 300),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(300, len(set(y_train)))\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "evaluate_model(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество обучаемых параметров: 22218\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Количество обучаемых параметров: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.1282, Test Loss: 1.1965\n",
      "Epoch 2, Train Loss: 1.1144, Test Loss: 1.2103\n",
      "Epoch 3, Train Loss: 1.1007, Test Loss: 1.2011\n",
      "Epoch 4, Train Loss: 1.0910, Test Loss: 1.1727\n",
      "Epoch 5, Train Loss: 1.0785, Test Loss: 1.1913\n",
      "Epoch 6, Train Loss: 1.0692, Test Loss: 1.1388\n",
      "Epoch 7, Train Loss: 1.0590, Test Loss: 1.1575\n",
      "Epoch 8, Train Loss: 1.0473, Test Loss: 1.1434\n",
      "Epoch 9, Train Loss: 1.0393, Test Loss: 1.1703\n",
      "Epoch 10, Train Loss: 1.0278, Test Loss: 1.1347\n",
      "Epoch 11, Train Loss: 1.0210, Test Loss: 1.1274\n",
      "Epoch 12, Train Loss: 1.0143, Test Loss: 1.1391\n",
      "Epoch 13, Train Loss: 1.0048, Test Loss: 1.1413\n",
      "Epoch 14, Train Loss: 0.9976, Test Loss: 1.1587\n",
      "Epoch 15, Train Loss: 0.9884, Test Loss: 1.1193\n",
      "Epoch 16, Train Loss: 0.9838, Test Loss: 1.1161\n",
      "Epoch 17, Train Loss: 0.9760, Test Loss: 1.1453\n",
      "Epoch 18, Train Loss: 0.9688, Test Loss: 1.1079\n",
      "Epoch 19, Train Loss: 0.9612, Test Loss: 1.1227\n",
      "Epoch 20, Train Loss: 0.9567, Test Loss: 1.1050\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_dataloader, test_dataloader, criterion, optimizer, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.67532\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.81      0.67       567\n",
      "           1       0.36      0.11      0.17        36\n",
      "           2       0.72      0.93      0.81       346\n",
      "           3       0.71      0.78      0.75       482\n",
      "           4       0.75      0.55      0.63       161\n",
      "           5       0.39      0.61      0.47        36\n",
      "           6       0.52      0.43      0.47       108\n",
      "           7       0.22      0.06      0.10        81\n",
      "           8       0.73      0.20      0.31        41\n",
      "           9       0.61      0.24      0.34       118\n",
      "          10       0.71      0.38      0.49        32\n",
      "          11       0.67      0.21      0.32        57\n",
      "          12       0.75      0.36      0.49        25\n",
      "          13       0.75      0.12      0.21        49\n",
      "          14       0.00      0.00      0.00        15\n",
      "          15       0.00      0.00      0.00        15\n",
      "          16       0.00      0.00      0.00        14\n",
      "          17       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.64      2196\n",
      "   macro avg       0.47      0.32      0.35      2196\n",
      "weighted avg       0.62      0.64      0.60      2196\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True)\n",
    "X_batch, y_batch = next(iter(test_loader))\n",
    "predictions = model(X_batch).argmax(dim=1).cpu().detach()\n",
    "print(classification_report(y_batch, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0.])\n",
      "fox: English (0.3876), Chinese (0.2666), French (0.0572)\n"
     ]
    }
   ],
   "source": [
    "predict(model, train_dataset, \"fox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 1.,\n",
      "        0.])\n",
      "balinyan: Russian (0.8657), English (0.0593), Irish (0.0340)\n"
     ]
    }
   ],
   "source": [
    "predict(model, train_dataset, \"balinyan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0.])\n",
      "valyaev: Russian (0.8590), English (0.0774), Czech (0.0384)\n"
     ]
    }
   ],
   "source": [
    "predict(model, train_dataset, \"valyaev\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PLmDB3fJtVox",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Классификация обзоров ресторанов\n",
    "\n",
    "Датасет: https://disk.yandex.ru/d/nY1o70JtAuYa8g\n",
    "\n",
    "3.1 Считать файл `yelp/raw_train.csv`. Оставить от исходного датасета 10% строчек.\n",
    "\n",
    "3.2 Воспользоваться функцией `preprocess_text` из 1.1 для обработки текста отзыва. Закодировать рейтинг числами, начиная с 0.\n",
    "\n",
    "3.3 Разбить датасет на обучающую и тестовую выборку\n",
    "\n",
    "3.4 Реализовать класс `Vocab` (токен = слово)\n",
    "\n",
    "3.5 Реализовать класс `ReviewDataset`\n",
    "\n",
    "3.6 Обучить классификатор\n",
    "\n",
    "3.7 Измерить точность на тестовой выборке. Проверить работоспособность модели: придумать небольшой отзыв, прогнать его через модель и вывести номер предсказанного класса (сделать это для явно позитивного и явно негативного отзыва)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([' ' if not char.isalpha() and char not in ['.', ',', '!', '?', \"'\"] else char for char in text])\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    preprocessed_text = ' '.join(lemmatized_tokens)\n",
    "\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Unfortunately, the frustration of being Dr. Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Been going to Dr. Goldberg for over 10 years. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>All the food is great here. But the best thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559995</th>\n",
       "      <td>2</td>\n",
       "      <td>Ryan was as good as everyone on yelp has claim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559996</th>\n",
       "      <td>2</td>\n",
       "      <td>Professional \\nFriendly\\nOn time AND affordabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559997</th>\n",
       "      <td>1</td>\n",
       "      <td>Phone calls always go to voicemail and message...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559998</th>\n",
       "      <td>1</td>\n",
       "      <td>Looks like all of the good reviews have gone t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559999</th>\n",
       "      <td>2</td>\n",
       "      <td>Ryan Rocks! I called him this morning for some...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating                                             review\n",
       "0            1  Unfortunately, the frustration of being Dr. Go...\n",
       "1            2  Been going to Dr. Goldberg for over 10 years. ...\n",
       "2            1  I don't know what Dr. Goldberg was like before...\n",
       "3            1  I'm writing this review to give you a heads up...\n",
       "4            2  All the food is great here. But the best thing...\n",
       "...        ...                                                ...\n",
       "559995       2  Ryan was as good as everyone on yelp has claim...\n",
       "559996       2  Professional \\nFriendly\\nOn time AND affordabl...\n",
       "559997       1  Phone calls always go to voicemail and message...\n",
       "559998       1  Looks like all of the good reviews have gone t...\n",
       "559999       2  Ryan Rocks! I called him this morning for some...\n",
       "\n",
       "[560000 rows x 2 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train = pd.read_csv(\"data/yelp/raw_train.csv\", names=[\"rating\", \"review\"])\n",
    "raw_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21691</th>\n",
       "      <td>1</td>\n",
       "      <td>Horrible horrible horrible! Worst nail place E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21692</th>\n",
       "      <td>1</td>\n",
       "      <td>I went in her for the first time today for a g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating                                             review\n",
       "21691       1  Horrible horrible horrible! Worst nail place E...\n",
       "21692       1  I went in her for the first time today for a g..."
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train[21691:21693]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>539138</th>\n",
       "      <td>2</td>\n",
       "      <td>great view and wonderful patio . service wa te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318337</th>\n",
       "      <td>1</td>\n",
       "      <td>my husband and i stayed here during the memori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437652</th>\n",
       "      <td>2</td>\n",
       "      <td>my husband and i were catching a show at the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130931</th>\n",
       "      <td>2</td>\n",
       "      <td>what 's really awesome with chase field ? ? ? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233880</th>\n",
       "      <td>1</td>\n",
       "      <td>they need to get rid of justin ... just plain ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118665</th>\n",
       "      <td>1</td>\n",
       "      <td>my wife and i are sushi buff . after reading s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259466</th>\n",
       "      <td>1</td>\n",
       "      <td>hate this airport the limited food option are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314501</th>\n",
       "      <td>2</td>\n",
       "      <td>my family stay at the holiday inn all the time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242185</th>\n",
       "      <td>2</td>\n",
       "      <td>fun place to go get drink , dance and enjoy th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275248</th>\n",
       "      <td>2</td>\n",
       "      <td>they 've remodeled this location so i 've deci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating                                             review\n",
       "539138       2  great view and wonderful patio . service wa te...\n",
       "318337       1  my husband and i stayed here during the memori...\n",
       "437652       2  my husband and i were catching a show at the s...\n",
       "130931       2  what 's really awesome with chase field ? ? ? ...\n",
       "233880       1  they need to get rid of justin ... just plain ...\n",
       "...        ...                                                ...\n",
       "118665       1  my wife and i are sushi buff . after reading s...\n",
       "259466       1  hate this airport the limited food option are ...\n",
       "314501       2  my family stay at the holiday inn all the time...\n",
       "242185       2  fun place to go get drink , dance and enjoy th...\n",
       "275248       2  they 've remodeled this location so i 've deci...\n",
       "\n",
       "[2800 rows x 2 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выбор 10% случайных строк\n",
    "raw_train_10 = raw_train.sample(frac=0.005)\n",
    "raw_train_10[\"review\"] = raw_train_10[\"review\"].apply(lambda x: preprocess_text(x))\n",
    "raw_train_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>539138</th>\n",
       "      <td>0</td>\n",
       "      <td>great view and wonderful patio . service wa te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318337</th>\n",
       "      <td>1</td>\n",
       "      <td>my husband and i stayed here during the memori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437652</th>\n",
       "      <td>0</td>\n",
       "      <td>my husband and i were catching a show at the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130931</th>\n",
       "      <td>0</td>\n",
       "      <td>what 's really awesome with chase field ? ? ? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233880</th>\n",
       "      <td>1</td>\n",
       "      <td>they need to get rid of justin ... just plain ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118665</th>\n",
       "      <td>1</td>\n",
       "      <td>my wife and i are sushi buff . after reading s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259466</th>\n",
       "      <td>1</td>\n",
       "      <td>hate this airport the limited food option are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314501</th>\n",
       "      <td>0</td>\n",
       "      <td>my family stay at the holiday inn all the time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242185</th>\n",
       "      <td>0</td>\n",
       "      <td>fun place to go get drink , dance and enjoy th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275248</th>\n",
       "      <td>0</td>\n",
       "      <td>they 've remodeled this location so i 've deci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating                                             review\n",
       "539138       0  great view and wonderful patio . service wa te...\n",
       "318337       1  my husband and i stayed here during the memori...\n",
       "437652       0  my husband and i were catching a show at the s...\n",
       "130931       0  what 's really awesome with chase field ? ? ? ...\n",
       "233880       1  they need to get rid of justin ... just plain ...\n",
       "...        ...                                                ...\n",
       "118665       1  my wife and i are sushi buff . after reading s...\n",
       "259466       1  hate this airport the limited food option are ...\n",
       "314501       0  my family stay at the holiday inn all the time...\n",
       "242185       0  fun place to go get drink , dance and enjoy th...\n",
       "275248       0  they 've remodeled this location so i 've deci...\n",
       "\n",
       "[2800 rows x 2 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_10['rating'], rating_labels = pd.factorize(raw_train_10['rating'])\n",
    "raw_train_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([2, 1], dtype='int64')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "_lCTSKZgu68K",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15925"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Vocab:\n",
    "  def __init__(self, data):\n",
    "    self.idx_to_token = {}\n",
    "    self.token_to_idx = {}\n",
    "    self.vocab_len = 0\n",
    "\n",
    "    # Получаем список всех слов в данных\n",
    "    all_words = [word for sentence in data[\"review\"] for word in word_tokenize(sentence)]\n",
    "\n",
    "    # Строим словарь\n",
    "    for word in all_words:\n",
    "        if word not in self.token_to_idx:\n",
    "            self.idx_to_token[self.vocab_len] = word\n",
    "            self.token_to_idx[word] = self.vocab_len\n",
    "            self.vocab_len += 1\n",
    "\n",
    "vocab = Vocab(raw_train_10)\n",
    "vocab.vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'great',\n",
       " 1: 'view',\n",
       " 2: 'and',\n",
       " 3: 'wonderful',\n",
       " 4: 'patio',\n",
       " 5: '.',\n",
       " 6: 'service',\n",
       " 7: 'wa',\n",
       " 8: 'terrible',\n",
       " 9: ',',\n",
       " 10: 'waitress',\n",
       " 11: 'did',\n",
       " 12: 'not',\n",
       " 13: 'write',\n",
       " 14: 'anything',\n",
       " 15: 'down',\n",
       " 16: 'we',\n",
       " 17: 'had',\n",
       " 18: 'a',\n",
       " 19: 'table',\n",
       " 20: 'of',\n",
       " 21: 'u',\n",
       " 22: 'she',\n",
       " 23: 'screwed',\n",
       " 24: 'everything',\n",
       " 25: 'up',\n",
       " 26: 'would',\n",
       " 27: 'only',\n",
       " 28: 'bring',\n",
       " 29: 'drink',\n",
       " 30: 'at',\n",
       " 31: 'time',\n",
       " 32: 'ordered',\n",
       " 33: 'food',\n",
       " 34: 'it',\n",
       " 35: 'came',\n",
       " 36: 'out',\n",
       " 37: 'forgot',\n",
       " 38: 'to',\n",
       " 39: 'put',\n",
       " 40: 'order',\n",
       " 41: 'in',\n",
       " 42: 'for',\n",
       " 43: 'some',\n",
       " 44: 'mediocre',\n",
       " 45: 'best',\n",
       " 46: 'thing',\n",
       " 47: 'is',\n",
       " 48: 'the',\n",
       " 49: 'eat',\n",
       " 50: 'there',\n",
       " 51: 'again',\n",
       " 52: 'but',\n",
       " 53: 'have',\n",
       " 54: 'hang',\n",
       " 55: 'they',\n",
       " 56: 'an',\n",
       " 57: 'awesome',\n",
       " 58: 'acoustic',\n",
       " 59: 'guitar',\n",
       " 60: 'player',\n",
       " 61: 'shame',\n",
       " 62: 'him',\n",
       " 63: 'that',\n",
       " 64: 'saw',\n",
       " 65: 'people',\n",
       " 66: 'leave',\n",
       " 67: 'due',\n",
       " 68: 'my',\n",
       " 69: 'husband',\n",
       " 70: 'i',\n",
       " 71: 'stayed',\n",
       " 72: 'here',\n",
       " 73: 'during',\n",
       " 74: 'memorial',\n",
       " 75: 'day',\n",
       " 76: 'weekend',\n",
       " 77: 'overall',\n",
       " 78: 'hotel',\n",
       " 79: 'very',\n",
       " 80: 'nice',\n",
       " 81: 'room',\n",
       " 82: 'are',\n",
       " 83: 'well',\n",
       " 84: 'appointed',\n",
       " 85: 'big',\n",
       " 86: 'shower',\n",
       " 87: 'with',\n",
       " 88: 'bench',\n",
       " 89: 'dark',\n",
       " 90: 'wood',\n",
       " 91: 'cabinetry',\n",
       " 92: 'plenty',\n",
       " 93: 'space',\n",
       " 94: 'store',\n",
       " 95: 'your',\n",
       " 96: 'clothes',\n",
       " 97: 'also',\n",
       " 98: 'cool',\n",
       " 99: 'digital',\n",
       " 100: 'from',\n",
       " 101: 'opening',\n",
       " 102: 'curtain',\n",
       " 103: 'turning',\n",
       " 104: 'on',\n",
       " 105: 'ac',\n",
       " 106: 'off',\n",
       " 107: 'bathroom',\n",
       " 108: 'light',\n",
       " 109: 'even',\n",
       " 110: 'housekeeping',\n",
       " 111: '!',\n",
       " 112: 'n',\n",
       " 113: 'nthe',\n",
       " 114: 'small',\n",
       " 115: 'so',\n",
       " 116: \"'s\",\n",
       " 117: 'separate',\n",
       " 118: 'area',\n",
       " 119: 'toilet',\n",
       " 120: 'separated',\n",
       " 121: 'by',\n",
       " 122: 'frosted',\n",
       " 123: 'glass',\n",
       " 124: 'which',\n",
       " 125: 'way',\n",
       " 126: 'you',\n",
       " 127: 'can',\n",
       " 128: 'still',\n",
       " 129: 'see',\n",
       " 130: 'through',\n",
       " 131: 'good',\n",
       " 132: 'just',\n",
       " 133: 'me',\n",
       " 134: 'hubby',\n",
       " 135: 'recommend',\n",
       " 136: 'this',\n",
       " 137: 'group',\n",
       " 138: 'nhowever',\n",
       " 139: 'like',\n",
       " 140: 'all',\n",
       " 141: 'other',\n",
       " 142: 'city',\n",
       " 143: 'center',\n",
       " 144: 'far',\n",
       " 145: 'casino',\n",
       " 146: 'caesar',\n",
       " 147: 'palace',\n",
       " 148: 'or',\n",
       " 149: 'venetian',\n",
       " 150: 'if',\n",
       " 151: 'want',\n",
       " 152: 'walk',\n",
       " 153: 'planet',\n",
       " 154: 'hollywood',\n",
       " 155: 'stair',\n",
       " 156: 'then',\n",
       " 157: 'upstairs',\n",
       " 158: 'downstairs',\n",
       " 159: 'nanother',\n",
       " 160: 'downside',\n",
       " 161: 'our',\n",
       " 162: 'nd',\n",
       " 163: 'night',\n",
       " 164: 'staying',\n",
       " 165: 'never',\n",
       " 166: 'made',\n",
       " 167: 'left',\n",
       " 168: 'around',\n",
       " 169: 'a.m.',\n",
       " 170: 'were',\n",
       " 171: 'back',\n",
       " 172: 'p.m.',\n",
       " 173: 'found',\n",
       " 174: 'though',\n",
       " 175: 'whole',\n",
       " 176: 'figured',\n",
       " 177: \"'re\",\n",
       " 178: 'leaving',\n",
       " 179: 'couple',\n",
       " 180: 'minute',\n",
       " 181: 'no',\n",
       " 182: 'deal',\n",
       " 183: 'will',\n",
       " 184: 'get',\n",
       " 185: 'serviced',\n",
       " 186: 'later',\n",
       " 187: 'when',\n",
       " 188: 'returned',\n",
       " 189: 'nothing',\n",
       " 190: 'finally',\n",
       " 191: 'call',\n",
       " 192: 'front',\n",
       " 193: 'desk',\n",
       " 194: 'let',\n",
       " 195: 'them',\n",
       " 196: 'know',\n",
       " 197: 'immediately',\n",
       " 198: 'asked',\n",
       " 199: 'said',\n",
       " 200: 'yes',\n",
       " 201: 'right',\n",
       " 202: 'away',\n",
       " 203: 'eventually',\n",
       " 204: 'expect',\n",
       " 205: 'something',\n",
       " 206: 'palazzo',\n",
       " 207: 'bellagio',\n",
       " 208: 'noverall',\n",
       " 209: 'stay',\n",
       " 210: 'new',\n",
       " 211: 'nicer',\n",
       " 212: 'better',\n",
       " 213: 'strip',\n",
       " 214: 'catching',\n",
       " 215: 'show',\n",
       " 216: 'smith',\n",
       " 217: \"n't\",\n",
       " 218: 'sit',\n",
       " 219: 'lunch',\n",
       " 220: 'decided',\n",
       " 221: 'mix',\n",
       " 222: 'try',\n",
       " 223: 'viva',\n",
       " 224: 'transported',\n",
       " 225: 'another',\n",
       " 226: 'country',\n",
       " 227: 'interior',\n",
       " 228: 'orange',\n",
       " 229: 'yellow',\n",
       " 230: 'spanish',\n",
       " 231: 'music',\n",
       " 232: 'radio',\n",
       " 233: 'man',\n",
       " 234: 'behind',\n",
       " 235: 'counter',\n",
       " 236: 'cordial',\n",
       " 237: 'definitely',\n",
       " 238: 'business',\n",
       " 239: 'pork',\n",
       " 240: 'butt',\n",
       " 241: 'shredded',\n",
       " 242: 'beef',\n",
       " 243: 'share',\n",
       " 244: 'fried',\n",
       " 245: 'plantain',\n",
       " 246: 'mango',\n",
       " 247: 'chose',\n",
       " 248: 'booth',\n",
       " 249: 'waited',\n",
       " 250: 'number',\n",
       " 251: 'be',\n",
       " 252: 'called',\n",
       " 253: 'quick',\n",
       " 254: 'served',\n",
       " 255: 'tray',\n",
       " 256: 'squeeze',\n",
       " 257: 'bottle',\n",
       " 258: 'condiment',\n",
       " 259: 'side',\n",
       " 260: 'arepas',\n",
       " 261: 'absolutely',\n",
       " 262: 'delicious',\n",
       " 263: 'loved',\n",
       " 264: 'bun',\n",
       " 265: 'more',\n",
       " 266: 'thick',\n",
       " 267: 'crumbly',\n",
       " 268: 'corn',\n",
       " 269: 'tortilla',\n",
       " 270: 'delicate',\n",
       " 271: 'meat',\n",
       " 272: 'melt',\n",
       " 273: 'mouth',\n",
       " 274: 'cooked',\n",
       " 275: 'perfection',\n",
       " 276: 'stole',\n",
       " 277: 'few',\n",
       " 278: 'bite',\n",
       " 279: 'perfect',\n",
       " 280: 'favorite',\n",
       " 281: 'going',\n",
       " 282: 'fry',\n",
       " 283: 'next',\n",
       " 284: 'too',\n",
       " 285: 'sweet',\n",
       " 286: 'quench',\n",
       " 287: 'thirst',\n",
       " 288: 'hot',\n",
       " 289: 'vega',\n",
       " 290: 'price',\n",
       " 291: 'soon',\n",
       " 292: 'what',\n",
       " 293: 'really',\n",
       " 294: 'chase',\n",
       " 295: 'field',\n",
       " 296: '?',\n",
       " 297: 'much',\n",
       " 298: 'beverage',\n",
       " 299: 'nsee',\n",
       " 300: '..',\n",
       " 301: 'life',\n",
       " 302: 'option',\n",
       " 303: '...',\n",
       " 304: 'either',\n",
       " 305: 'spend',\n",
       " 306: 'overpriced',\n",
       " 307: 'water',\n",
       " 308: 'buy',\n",
       " 309: 'lady',\n",
       " 310: 'intersection',\n",
       " 311: 'outside',\n",
       " 312: 'ballpark',\n",
       " 313: 'save',\n",
       " 314: 'pocket',\n",
       " 315: 'nmy',\n",
       " 316: 'boyfriend',\n",
       " 317: 'play',\n",
       " 318: 'minor',\n",
       " 319: 'league',\n",
       " 320: 'team',\n",
       " 321: 'hence',\n",
       " 322: 'he',\n",
       " 323: 'free',\n",
       " 324: 'complimentary',\n",
       " 325: 'ticket',\n",
       " 326: 'any',\n",
       " 327: 'major',\n",
       " 328: 'game',\n",
       " 329: 'his',\n",
       " 330: 'choice',\n",
       " 331: 'got',\n",
       " 332: 'high',\n",
       " 333: 'seat',\n",
       " 334: 'packed',\n",
       " 335: 'kinda',\n",
       " 336: 'sucked',\n",
       " 337: 'amazingly',\n",
       " 338: 'beautiful',\n",
       " 339: '....',\n",
       " 340: 'actually',\n",
       " 341: 'than',\n",
       " 342: 't',\n",
       " 343: 'park',\n",
       " 344: 'where',\n",
       " 345: 'belong',\n",
       " 346: 'maintained',\n",
       " 347: 'grass',\n",
       " 348: 'greener',\n",
       " 349: 'however',\n",
       " 350: 'le',\n",
       " 351: 'concession',\n",
       " 352: 'np',\n",
       " 353: 'foreigner',\n",
       " 354: 'make',\n",
       " 355: 'sure',\n",
       " 356: 'passport',\n",
       " 357: 'able',\n",
       " 358: 'alcohol',\n",
       " 359: 'canadian',\n",
       " 360: 'dl',\n",
       " 361: 'do',\n",
       " 362: 'beer',\n",
       " 363: 'buying',\n",
       " 364: 'nalso',\n",
       " 365: 'month',\n",
       " 366: 'may',\n",
       " 367: 'stadium',\n",
       " 368: 'roof',\n",
       " 369: 'open',\n",
       " 370: 'soooooo',\n",
       " 371: 'dress',\n",
       " 372: 'comfortably',\n",
       " 373: 'need',\n",
       " 374: 'rid',\n",
       " 375: 'justin',\n",
       " 376: 'plain',\n",
       " 377: 'rude',\n",
       " 378: \"'ve\",\n",
       " 379: 'been',\n",
       " 380: 'twice',\n",
       " 381: 'same',\n",
       " 382: 'friend',\n",
       " 383: 'both',\n",
       " 384: 'female',\n",
       " 385: 'early',\n",
       " 386: 'about',\n",
       " 387: 'place',\n",
       " 388: 'atmosphere',\n",
       " 389: 'decor',\n",
       " 390: 'half',\n",
       " 391: 'decent',\n",
       " 392: 'fantastic',\n",
       " 393: 'unimpressive',\n",
       " 394: 'worst',\n",
       " 395: 'part',\n",
       " 396: 'bartender',\n",
       " 397: 'two',\n",
       " 398: 'different',\n",
       " 399: 'one',\n",
       " 400: 'unattentive',\n",
       " 401: 'completely',\n",
       " 402: 'serving',\n",
       " 403: 'their',\n",
       " 404: 'attention',\n",
       " 405: 'waiting',\n",
       " 406: 'anyone',\n",
       " 407: 'else',\n",
       " 408: 'uninterested',\n",
       " 409: 'type',\n",
       " 410: 'conversation',\n",
       " 411: 'menu',\n",
       " 412: 'available',\n",
       " 413: 'seemed',\n",
       " 414: 'feel',\n",
       " 415: 'doing',\n",
       " 416: 'favor',\n",
       " 417: 'busy',\n",
       " 418: 'bar',\n",
       " 419: 'full',\n",
       " 420: 'second',\n",
       " 421: 'literally',\n",
       " 422: 'maybe',\n",
       " 423: 'seated',\n",
       " 424: 'entire',\n",
       " 425: 'ndo',\n",
       " 426: 'yourself',\n",
       " 427: 'go',\n",
       " 428: 'ibiza',\n",
       " 429: 'mallorca',\n",
       " 430: 'tapa',\n",
       " 431: 'intimate',\n",
       " 432: 'wine',\n",
       " 433: 'list',\n",
       " 434: 'impeccable',\n",
       " 435: 'find',\n",
       " 436: 'went',\n",
       " 437: 'girlfriend',\n",
       " 438: 'over',\n",
       " 439: 'delighted',\n",
       " 440: 'extra',\n",
       " 441: 'treat',\n",
       " 442: 'feminine',\n",
       " 443: 'industrial',\n",
       " 444: 'chic',\n",
       " 445: 'd',\n",
       " 446: 'e',\n",
       " 447: 'cor',\n",
       " 448: 'rather',\n",
       " 449: 'large',\n",
       " 450: 'owner',\n",
       " 451: 'samantha',\n",
       " 452: 'incredibly',\n",
       " 453: 'welcoming',\n",
       " 454: 'attentive',\n",
       " 455: 'mini',\n",
       " 456: 'tres',\n",
       " 457: 'lech',\n",
       " 458: 'cake',\n",
       " 459: 'size',\n",
       " 460: 'milky',\n",
       " 461: 'without',\n",
       " 462: 'being',\n",
       " 463: 'soggy',\n",
       " 464: 'key',\n",
       " 465: 'lime',\n",
       " 466: 'tanginess',\n",
       " 467: 'delightful',\n",
       " 468: 'complement',\n",
       " 469: 'creaminess',\n",
       " 470: 'flavor',\n",
       " 471: 'hard',\n",
       " 472: 'top',\n",
       " 473: 'pecan',\n",
       " 474: 'butter',\n",
       " 475: 'cooky',\n",
       " 476: 'lemon',\n",
       " 477: 'now',\n",
       " 478: 'decide',\n",
       " 479: 'expensive',\n",
       " 480: 'suck',\n",
       " 481: 'ambiance',\n",
       " 482: 'fun',\n",
       " 483: 'deliver',\n",
       " 484: 'bland',\n",
       " 485: 'expected',\n",
       " 486: 'plus',\n",
       " 487: \"'m\",\n",
       " 488: 'paying',\n",
       " 489: 'arm',\n",
       " 490: 'leg',\n",
       " 491: 'thanks',\n",
       " 492: 'those',\n",
       " 493: 'giant',\n",
       " 494: 'cocktail',\n",
       " 495: 'pretty',\n",
       " 496: 'neat',\n",
       " 497: 'waiter',\n",
       " 498: 'ever',\n",
       " 499: 'ni',\n",
       " 500: 'come',\n",
       " 501: 'tgifriday',\n",
       " 502: 'always',\n",
       " 503: 'today',\n",
       " 504: 'beyond',\n",
       " 505: 'horrible',\n",
       " 506: 'sister',\n",
       " 507: 'usually',\n",
       " 508: 'dining',\n",
       " 509: 'empty',\n",
       " 510: 'host',\n",
       " 511: 'suggested',\n",
       " 512: 'since',\n",
       " 513: 'happy',\n",
       " 514: 'hour',\n",
       " 515: 'why',\n",
       " 516: 'crystal',\n",
       " 517: 'bread',\n",
       " 518: 'stick',\n",
       " 519: 'appetizer',\n",
       " 520: 'took',\n",
       " 521: 'while',\n",
       " 522: 'mind',\n",
       " 523: 'brought',\n",
       " 524: 'refill',\n",
       " 525: 'disappeared',\n",
       " 526: 'cut',\n",
       " 527: 'into',\n",
       " 528: 'steak',\n",
       " 529: 'blood',\n",
       " 530: 'gushing',\n",
       " 531: 'medium',\n",
       " 532: 'should',\n",
       " 533: 'little',\n",
       " 534: 'pink',\n",
       " 535: 'coming',\n",
       " 536: 'basically',\n",
       " 537: 'rare',\n",
       " 538: 'her',\n",
       " 539: 'could',\n",
       " 540: 'ate',\n",
       " 541: 'because',\n",
       " 542: 'hungry',\n",
       " 543: 'cold',\n",
       " 544: 'anymore',\n",
       " 545: 'nor',\n",
       " 546: 'wait',\n",
       " 547: 'fixed',\n",
       " 548: 'plate',\n",
       " 549: 'clear',\n",
       " 550: 'upset',\n",
       " 551: 'needed',\n",
       " 552: 'box',\n",
       " 553: 'pissed',\n",
       " 554: 'point',\n",
       " 555: 'care',\n",
       " 556: 'wanted',\n",
       " 557: 'eating',\n",
       " 558: 'drinking',\n",
       " 559: 'soda',\n",
       " 560: 'disgusting',\n",
       " 561: 'almost',\n",
       " 562: 'spit',\n",
       " 563: 'done',\n",
       " 564: 'brings',\n",
       " 565: 'check',\n",
       " 566: 'take',\n",
       " 567: 'clearly',\n",
       " 568: 'untouched',\n",
       " 569: 'bothering',\n",
       " 570: 'ask',\n",
       " 571: 'wrong',\n",
       " 572: 'pay',\n",
       " 573: 'give',\n",
       " 574: 'note',\n",
       " 575: 'manager',\n",
       " 576: 'real',\n",
       " 577: 'apologized',\n",
       " 578: 'think',\n",
       " 579: 'location',\n",
       " 580: 'wo',\n",
       " 581: 'waste',\n",
       " 582: 'money',\n",
       " 583: 'looking',\n",
       " 584: 'indian',\n",
       " 585: 'restaurant',\n",
       " 586: 'awhile',\n",
       " 587: 'look',\n",
       " 588: 'am',\n",
       " 589: 'keep',\n",
       " 590: 'staff',\n",
       " 591: 'unfriendly',\n",
       " 592: 'saying',\n",
       " 593: 'welcome',\n",
       " 594: 'how',\n",
       " 595: 'itself',\n",
       " 596: 'okay',\n",
       " 597: 'worth',\n",
       " 598: 'redeeming',\n",
       " 599: 'item',\n",
       " 600: 'rice',\n",
       " 601: 'pudding',\n",
       " 602: 'desert',\n",
       " 603: 'tell',\n",
       " 604: 'ryan',\n",
       " 605: 'adam',\n",
       " 606: 'lyric',\n",
       " 607: 'head',\n",
       " 608: 'uptown',\n",
       " 609: \"n'cause\",\n",
       " 610: 'star',\n",
       " 611: 'nand',\n",
       " 612: 'making',\n",
       " 613: 'noda',\n",
       " 614: 'nto',\n",
       " 615: 'drunk',\n",
       " 616: 'worry',\n",
       " 617: 'written',\n",
       " 618: 'face',\n",
       " 619: 'ndespite',\n",
       " 620: 'before',\n",
       " 621: 'sha',\n",
       " 622: 'na',\n",
       " 623: 'la',\n",
       " 624: 'nso',\n",
       " 625: 'forget',\n",
       " 626: 'glitz',\n",
       " 627: 'most',\n",
       " 628: 'charlotte',\n",
       " 629: 'pesto',\n",
       " 630: 'sandwich',\n",
       " 631: 'delish',\n",
       " 632: 'taco',\n",
       " 633: 'bomb',\n",
       " 634: 'especially',\n",
       " 635: 'lamb',\n",
       " 636: 'eggplant',\n",
       " 637: 'goat',\n",
       " 638: 'cheese',\n",
       " 639: 'w',\n",
       " 640: 'mac',\n",
       " 641: 'love',\n",
       " 642: 'thinking',\n",
       " 643: 'dreaming',\n",
       " 644: 'lol',\n",
       " 645: 'fiance',\n",
       " 646: 'last',\n",
       " 647: 'special',\n",
       " 648: 'sirloin',\n",
       " 649: 'kabob',\n",
       " 650: 'natural',\n",
       " 651: 'crinkle',\n",
       " 652: 'streak',\n",
       " 653: 'told',\n",
       " 654: 'who',\n",
       " 655: 'friendly',\n",
       " 656: 'cheesy',\n",
       " 657: 'cheeseburger',\n",
       " 658: 'lettuce',\n",
       " 659: 'tomato',\n",
       " 660: 'repeated',\n",
       " 661: 'fast',\n",
       " 662: 'arrived',\n",
       " 663: 'mashed',\n",
       " 664: 'potato',\n",
       " 665: 'gravy',\n",
       " 666: 'burger',\n",
       " 667: 'dripping',\n",
       " 668: 'grease',\n",
       " 669: 'yucky',\n",
       " 670: 'cheap',\n",
       " 671: 'carl',\n",
       " 672: 'jr',\n",
       " 673: 'commercial',\n",
       " 674: 'rambo',\n",
       " 675: 'kitchen',\n",
       " 676: 'tried',\n",
       " 677: 'signature',\n",
       " 678: 'goblet',\n",
       " 679: 'piece',\n",
       " 680: 'understand',\n",
       " 681: 'novelty',\n",
       " 682: 'pre',\n",
       " 683: 'drank',\n",
       " 684: 'marveled',\n",
       " 685: 'wonder',\n",
       " 686: 'fishbowl',\n",
       " 687: 'style',\n",
       " 688: 'candy',\n",
       " 689: 'sober',\n",
       " 690: 'totally',\n",
       " 691: 'appreciate',\n",
       " 692: 'bell',\n",
       " 693: 'whistle',\n",
       " 694: 'dur',\n",
       " 695: 'volume',\n",
       " 696: 'probably',\n",
       " 697: 'myself',\n",
       " 698: 'cost',\n",
       " 699: 'dry',\n",
       " 700: 'ice',\n",
       " 701: 'wise',\n",
       " 702: 'eh',\n",
       " 703: 'used',\n",
       " 704: 'sense',\n",
       " 705: 'bbq',\n",
       " 706: 'pizza',\n",
       " 707: 'hype',\n",
       " 708: 'mean',\n",
       " 709: 'cute',\n",
       " 710: 'downtown',\n",
       " 711: 'tempe',\n",
       " 712: 'getting',\n",
       " 713: 'flyer',\n",
       " 714: 'gu',\n",
       " 715: 'taped',\n",
       " 716: 'onto',\n",
       " 717: 'door',\n",
       " 718: 'year',\n",
       " 719: 'ago',\n",
       " 720: 'wicked',\n",
       " 721: 'hunger',\n",
       " 722: 'smack',\n",
       " 723: 'shot',\n",
       " 724: 'ngu',\n",
       " 725: 'scream',\n",
       " 726: 'online',\n",
       " 727: 'ordering',\n",
       " 728: 'wandered',\n",
       " 729: 'site',\n",
       " 730: 'thought',\n",
       " 731: \"'d\",\n",
       " 732: 'noticed',\n",
       " 733: 'delivery',\n",
       " 734: 'charge',\n",
       " 735: 'cent',\n",
       " 736: 'fee',\n",
       " 737: 'poor',\n",
       " 738: 'college',\n",
       " 739: 'student',\n",
       " 740: 'skip',\n",
       " 741: 'takeaway',\n",
       " 742: 'speak',\n",
       " 743: 'unintelligible',\n",
       " 744: 'knucklehead',\n",
       " 745: 'pepperoni',\n",
       " 746: 'sausage',\n",
       " 747: 'garlic',\n",
       " 748: 'using',\n",
       " 749: 'many',\n",
       " 750: 'coupon',\n",
       " 751: 'collected',\n",
       " 752: 'say',\n",
       " 753: 'twenty',\n",
       " 754: 'thank',\n",
       " 755: 'chuckle',\n",
       " 756: 'amusing',\n",
       " 757: 'youtube',\n",
       " 758: 'video',\n",
       " 759: 'ten',\n",
       " 760: 'five',\n",
       " 761: 'drive',\n",
       " 762: 'guarantee',\n",
       " 763: 'fresh',\n",
       " 764: 'oven',\n",
       " 765: 'hit',\n",
       " 766: 'delhi',\n",
       " 767: 'inside',\n",
       " 768: 'unimpressed',\n",
       " 769: 'mid',\n",
       " 770: 'forty',\n",
       " 771: 'guido',\n",
       " 772: 'complete',\n",
       " 773: 'slicked',\n",
       " 774: 'hair',\n",
       " 775: 'gold',\n",
       " 776: 'chain',\n",
       " 777: 'neck',\n",
       " 778: 'guy',\n",
       " 779: 'appeared',\n",
       " 780: 'trying',\n",
       " 781: 'avoid',\n",
       " 782: 'working',\n",
       " 783: 'turn',\n",
       " 784: 'chump',\n",
       " 785: 'whose',\n",
       " 786: 'job',\n",
       " 787: 'apparently',\n",
       " 788: 'yet',\n",
       " 789: 'tossed',\n",
       " 790: 'together',\n",
       " 791: 'threw',\n",
       " 792: \"'ll\",\n",
       " 793: 'ready',\n",
       " 794: 'cash',\n",
       " 795: 'listen',\n",
       " 796: 'banter',\n",
       " 797: 'between',\n",
       " 798: 'disturbing',\n",
       " 799: 'douchebag',\n",
       " 800: 'woman',\n",
       " 801: 'shorter',\n",
       " 802: 'dominate',\n",
       " 803: 'mother',\n",
       " 804: 'watch',\n",
       " 805: 'daughter',\n",
       " 806: 'asu',\n",
       " 807: 'junior',\n",
       " 808: 'after',\n",
       " 809: 'angry',\n",
       " 810: 'bird',\n",
       " 811: 'home',\n",
       " 812: 'popped',\n",
       " 813: 'topping',\n",
       " 814: 'smell',\n",
       " 815: 'use',\n",
       " 816: 'magical',\n",
       " 817: 'ingredient',\n",
       " 818: 'review',\n",
       " 819: 'sockpuppets',\n",
       " 820: 'reviewed',\n",
       " 821: 'instead',\n",
       " 822: 'crust',\n",
       " 823: 'oversweet',\n",
       " 824: 'sauce',\n",
       " 825: 'form',\n",
       " 826: 'dried',\n",
       " 827: 'chunk',\n",
       " 828: 'expecting',\n",
       " 829: 'meh',\n",
       " 830: 'tombstone',\n",
       " 831: 'quality',\n",
       " 832: 'nit',\n",
       " 833: 'important',\n",
       " 834: 'safely',\n",
       " 835: 'late',\n",
       " 836: 'ha',\n",
       " 837: 'gotten',\n",
       " 838: 'club',\n",
       " 839: 'nthis',\n",
       " 840: 'opposite',\n",
       " 841: 'nwalking',\n",
       " 842: 'given',\n",
       " 843: 'card',\n",
       " 844: 'entry',\n",
       " 845: 'midnight',\n",
       " 846: 'pm',\n",
       " 847: 'barely',\n",
       " 848: 'line',\n",
       " 849: 'disappointment',\n",
       " 850: 'seen',\n",
       " 851: 'entering',\n",
       " 852: 'compared',\n",
       " 853: 'nthere',\n",
       " 854: 'vip',\n",
       " 855: 'section',\n",
       " 856: 'bouncer',\n",
       " 857: 'anal',\n",
       " 858: 'stand',\n",
       " 859: 'near',\n",
       " 860: 'exit',\n",
       " 861: 'three',\n",
       " 862: 'vigilant',\n",
       " 863: 'kick',\n",
       " 864: 'numerous',\n",
       " 865: 'explain',\n",
       " 866: 'problem',\n",
       " 867: 'rok',\n",
       " 868: 'enjoy',\n",
       " 869: 'unisex',\n",
       " 870: 'nsmall',\n",
       " 871: 'definition',\n",
       " 872: 'michelin',\n",
       " 873: 'noh',\n",
       " 874: 'such',\n",
       " 875: 'town',\n",
       " 876: 'indulgence',\n",
       " 877: 'gluttony',\n",
       " 878: 'savoy',\n",
       " 879: 'pronounced',\n",
       " 880: 'chosen',\n",
       " 881: 'dinner',\n",
       " 882: 'wife',\n",
       " 883: 'reason',\n",
       " 884: 'live',\n",
       " 885: 'nbeing',\n",
       " 886: 'old',\n",
       " 887: 'married',\n",
       " 888: 'knowing',\n",
       " 889: 'earliest',\n",
       " 890: 'reservation',\n",
       " 891: 'grand',\n",
       " 892: 'upon',\n",
       " 893: 'arrival',\n",
       " 894: 'fountain',\n",
       " 895: 'south',\n",
       " 896: 'mostly',\n",
       " 897: 'white',\n",
       " 898: 'interrupted',\n",
       " 899: 'occasional',\n",
       " 900: 'ultra',\n",
       " 901: 'bright',\n",
       " 902: 'art',\n",
       " 903: 'glance',\n",
       " 904: 'considering',\n",
       " 905: 'innovation',\n",
       " 906: 'shared',\n",
       " 907: 'pairing',\n",
       " 908: 'foie',\n",
       " 909: 'toast',\n",
       " 910: 'amuse',\n",
       " 911: 'nwhat',\n",
       " 912: 'truffle',\n",
       " 913: 'crisp',\n",
       " 914: 'add',\n",
       " 915: 'texture',\n",
       " 916: 'hello',\n",
       " 917: 'having',\n",
       " 918: 'ear',\n",
       " 919: 'licked',\n",
       " 920: 'taste',\n",
       " 921: 'nhttp',\n",
       " 922: 'www.yelp.com',\n",
       " 923: 'biz',\n",
       " 924: 'photo',\n",
       " 925: 'q',\n",
       " 926: 'nzctmrztbohuzi',\n",
       " 927: 'iia',\n",
       " 928: 'waffle',\n",
       " 929: 'parmesan',\n",
       " 930: 'nkind',\n",
       " 931: 'weird',\n",
       " 932: 'god',\n",
       " 933: 'damn',\n",
       " 934: 'wow',\n",
       " 935: 'k',\n",
       " 936: 'hfoidwuhjqdk',\n",
       " 937: 'y',\n",
       " 938: 'ug',\n",
       " 939: 'cart',\n",
       " 940: 'ndude',\n",
       " 941: 'every',\n",
       " 942: 'single',\n",
       " 943: 'morning',\n",
       " 944: 'guess',\n",
       " 945: 'impressive',\n",
       " 946: 'consider',\n",
       " 947: 'army',\n",
       " 948: 'bowel',\n",
       " 949: 'these',\n",
       " 950: 'somewhere',\n",
       " 951: 'someone',\n",
       " 952: 'dozen',\n",
       " 953: 'artisanal',\n",
       " 954: 'selection',\n",
       " 955: 'course',\n",
       " 956: 'amazing',\n",
       " 957: 'ceipon',\n",
       " 958: 'mqyabwmccurhm',\n",
       " 959: 'ooos',\n",
       " 960: 'aaahhs',\n",
       " 961: 'kept',\n",
       " 962: 'must',\n",
       " 963: 'six',\n",
       " 964: 'intricate',\n",
       " 965: 'preparation',\n",
       " 966: 'combine',\n",
       " 967: 'highlighted',\n",
       " 968: 'vinegar',\n",
       " 969: 'masterfully',\n",
       " 970: 'finished',\n",
       " 971: 'nibble',\n",
       " 972: 'chip',\n",
       " 973: 'kgqj',\n",
       " 974: 'czz',\n",
       " 975: 'dtxure',\n",
       " 976: 'hmi',\n",
       " 977: 'wg',\n",
       " 978: 'concass',\n",
       " 979: 'oyster',\n",
       " 980: 'nconcasse',\n",
       " 981: 'french',\n",
       " 982: 'culinary',\n",
       " 983: 'word',\n",
       " 984: 'crushed',\n",
       " 985: 'ground',\n",
       " 986: 'dish',\n",
       " 987: 'topped',\n",
       " 988: 'seaweed',\n",
       " 989: 'granite',\n",
       " 990: 'perfectly',\n",
       " 991: 'chopped',\n",
       " 992: 'worked',\n",
       " 993: 'crunchy',\n",
       " 994: 'gvfhiudm',\n",
       " 995: 'qu',\n",
       " 996: 'dkxh',\n",
       " 997: 'xxtsa',\n",
       " 998: 'langoustine',\n",
       " 999: 'steam',\n",
       " ...}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.idx_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "  def __init__(self, X, y, vocab: Vocab):\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "    self.vocab = vocab\n",
    "\n",
    "  def vectorize(self, review):\n",
    "    '''Генерирует представление отзыва review при помощи бинарного кодирования (см. 1.2)'''\n",
    "    vec = torch.zeros(self.vocab.vocab_len)\n",
    "\n",
    "    # Проходим по каждому слову в фамилии\n",
    "    for word in word_tokenize(review):\n",
    "      # Если слово есть в словаре, устанавливаем соответствующий бит в векторе\n",
    "      if word in self.vocab.token_to_idx:\n",
    "          vec[self.vocab.token_to_idx[word]] = 1\n",
    "\n",
    "    return vec\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    vec = self.vectorize(self.X[idx])\n",
    "    label = self.y[idx]\n",
    "    return vec, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(raw_train_10['review'].to_numpy(), raw_train_10['rating'].to_numpy(), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = ReviewDataset(X_train, y_train, vocab)\n",
    "test_dataset = ReviewDataset(X_test, y_test, vocab)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(vocab.vocab_len, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 2),\n",
    "    nn.LogSoftmax(dim=1),\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15925"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=15925, out_features=1024, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  (3): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество обучаемых параметров: 16310274\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Количество обучаемых параметров: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.4011, Test Loss: 0.4024\n",
      "Epoch 2, Train Loss: 0.0653, Test Loss: 0.3874\n",
      "Epoch 3, Train Loss: 0.0136, Test Loss: 0.4331\n",
      "Epoch 4, Train Loss: 0.0035, Test Loss: 0.4785\n",
      "Epoch 5, Train Loss: 0.0014, Test Loss: 0.5232\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_dataloader, test_dataloader, criterion, optimizer, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rating_labels = [\"Positive\", \"Negative\"]\n",
    "\n",
    "def predict(model, dataset, review):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        vectorized = dataset.vectorize(review)\n",
    "        tensor = vectorized.unsqueeze(0).to(device)\n",
    "        logits = model(tensor)\n",
    "        probs = torch.softmax(logits, dim=1).squeeze()\n",
    "        print(probs)\n",
    "        print(f'{rating_labels[probs.argmax()]} ({probs.max():.4f}), {rating_labels[probs.argmin()]} ({probs.min():.4f}) \\n{review}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.87857\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88       290\n",
      "           1       0.86      0.89      0.88       270\n",
      "\n",
      "    accuracy                           0.88       560\n",
      "   macro avg       0.88      0.88      0.88       560\n",
      "weighted avg       0.88      0.88      0.88       560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True)\n",
    "X_batch, y_batch = next(iter(test_loader))\n",
    "predictions = model(X_batch).argmax(dim=1).cpu().detach()\n",
    "print(classification_report(y_batch, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.1828e-04, 9.9938e-01])\n",
      "Negative (0.9994), Positive (0.0006) \n",
      "I had a terrible experience at this restaurant. The staff was rude and the food was overpriced for the quality.\n"
     ]
    }
   ],
   "source": [
    "predict(model, train_dataset, \"I had a terrible experience at this restaurant. The staff was rude and the food was overpriced for the quality.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9953, 0.0047])\n",
      "Positive (0.9953), Negative (0.0047) \n",
      "I can't say enough good things about this restaurant. It's the perfect place for a romantic dinner or a night out with friends.\n"
     ]
    }
   ],
   "source": [
    "predict(model, train_dataset, \"I can't say enough good things about this restaurant. It's the perfect place for a romantic dinner or a night out with friends.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0221, 0.9779])\n",
      "Negative (0.9779), Positive (0.0221) \n",
      "The menu at this restaurant is very limited and the food is nothing special. I wouldn't go back.\n"
     ]
    }
   ],
   "source": [
    "predict(model, train_dataset, \"The menu at this restaurant is very limited and the food is nothing special. I wouldn't go back.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMJ70DQQj2X/XaG2BMq6jy8",
   "collapsed_sections": [],
   "name": "blank__05_NLP_1_intro.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
