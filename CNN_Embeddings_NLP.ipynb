{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6359,
     "status": "ok",
     "timestamp": 1681725010022,
     "user": {
      "displayName": "Владимир Калашников",
      "userId": "10309937654173354602"
     },
     "user_tz": -180
    },
    "id": "XtFQP3RNll3c",
    "outputId": "ef65051e-9af7-4f41-f52c-b769b9b1a036",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, nltk\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "tx75RigN8xIJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Представление и предобработка текстовых данных в виде последовательностей"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "LScKIAey9dAM",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1.1 Представьте первое предложение из строки `text` как последовательность из индексов слов, входящих в это предложение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "phEw721T9SYW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text = 'Select your preferences and run the install command. Stable represents the most currently tested and supported version of PyTorch. Note that LibTorch is only available for C++'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'note': 0, 'command': 1, 'only': 2, 'is': 3, 'preferences': 4, 'for': 5, 'stable': 6, 'install': 7, 'version': 8, 'run': 9, 'most': 10, 'that': 11, 'available': 12, 'libtorch': 13, 'of': 14, 'pytorch': 15, 'currently': 16, 'and': 17, 'tested': 18, 'c++': 19, 'select': 20, 'the': 21, '.': 22, 'represents': 23, 'your': 24, 'supported': 25}\n",
      "\n",
      "[20, 24, 4, 17, 9, 21, 7, 1, 22]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "words = word_tokenize(text.lower())\n",
    "unique_words = set(words)\n",
    "\n",
    "vocab = {word: i for i, word in enumerate(unique_words)}\n",
    "print(vocab)\n",
    "\n",
    "print()\n",
    "\n",
    "seq_1 = sent_tokenize(text.lower())[0]\n",
    "indexes = [vocab[word] for word in word_tokenize(seq_1)]\n",
    "print(indexes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "pSFQCPtD9x5J",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1.2 Представьте первое предложение из строки `text` как последовательность векторов, соответствующих индексам слов. Для представления индекса в виде вектора используйте унитарное кодирование. В результате должен получиться двумерный тензор размера `количество слов в предложении` x `количество уникальных слов`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "RZS4XLV0-buf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text = 'Select your preferences and run the install command. Stable represents the most currently tested and supported version of PyTorch. Note that LibTorch is only available for C++'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['select',\n",
       " 'your',\n",
       " 'preferences',\n",
       " 'and',\n",
       " 'run',\n",
       " 'the',\n",
       " 'install',\n",
       " 'command',\n",
       " '.']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent_tokenize(text)[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['select', 'your', 'preferences', 'and', 'run', 'the', 'install', 'command', '.', 'stable', 'represents', 'the', 'most', 'currently', 'tested', 'and', 'supported', 'version', 'of', 'pytorch', '.', 'note', 'that', 'libtorch', 'is', 'only', 'available', 'for', 'c++']\n",
      "\n",
      "{'that', 'is', 'c++', 'stable', 'note', 'available', 'only', 'tested', 'represents', 'preferences', 'of', 'libtorch', 'command', 'version', 'the', 'your', 'run', 'install', 'currently', 'select', 'and', 'for', 'most', 'pytorch', 'supported', '.'}\n",
      "26\n",
      "torch.Size([9, 26])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(text.lower())\n",
    "print(words)\n",
    "\n",
    "print()\n",
    "\n",
    "unique_words = set(words)\n",
    "print(unique_words)\n",
    "print(len(unique_words))\n",
    "\n",
    "vocab = {word: i for i, word in enumerate(unique_words)}\n",
    "\n",
    "one_hot = torch.eye(len(vocab))\n",
    "\n",
    "sentence_vectors = []\n",
    "for token in word_tokenize(sent_tokenize(text)[0].lower()):\n",
    "    index = vocab[token]\n",
    "    vector = one_hot[index]\n",
    "    sentence_vectors.append(vector)\n",
    "\n",
    "sentence_vectors = torch.stack(sentence_vectors)\n",
    "\n",
    "print(sentence_vectors.shape)\n",
    "print(sentence_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Select', 'your', 'preferences', 'and', 'run', 'the', 'install', 'command']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word_tokenize(word)[0] for word in sent_tokenize(text)[0].split()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZvQKHYA-mJN",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1.3 Решите задачу 1.2, используя модуль `nn.Embedding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "{'that', 'is', 'c++', 'stable', 'note', 'available', 'only', 'tested', 'represents', 'preferences', 'of', 'libtorch', 'command', 'version', 'the', 'your', 'run', 'install', 'currently', 'select', 'and', 'for', 'most', 'pytorch', 'supported', '.'}\n",
      "{'that': 0, 'is': 1, 'c++': 2, 'stable': 3, 'note': 4, 'available': 5, 'only': 6, 'tested': 7, 'represents': 8, 'preferences': 9, 'of': 10, 'libtorch': 11, 'command': 12, 'version': 13, 'the': 14, 'your': 15, 'run': 16, 'install': 17, 'currently': 18, 'select': 19, 'and': 20, 'for': 21, 'most': 22, 'pytorch': 23, 'supported': 24, '.': 25}\n",
      "9\n",
      "[19, 15, 9, 20, 16, 14, 17, 12, 25]\n",
      "torch.Size([9, 26])\n",
      "tensor([[-4.6437e-02, -1.0412e+00, -6.2842e-01, -2.0072e+00,  7.2855e-01,\n",
      "          1.4604e+00,  9.3112e-01, -1.4635e-01,  1.4755e+00, -3.6397e-01,\n",
      "          1.3493e+00, -3.4245e-01,  2.2404e-01,  1.1051e+00, -6.6909e-01,\n",
      "          1.6545e+00,  6.3852e-01,  4.9884e-01,  9.7245e-01,  1.8334e-02,\n",
      "         -1.4559e+00,  1.5422e+00,  1.7896e-02,  9.2047e-01, -2.2073e-02,\n",
      "          6.2112e-02],\n",
      "        [ 6.2837e-01,  1.0843e+00,  6.7559e-01, -2.7826e-02,  1.4544e+00,\n",
      "         -7.2054e-01, -7.7109e-01, -1.3497e-01, -6.0921e-01,  6.4330e-01,\n",
      "          4.7422e-02, -2.8169e-01,  7.0761e-01, -1.2789e+00, -6.4331e-01,\n",
      "         -4.3528e-01,  5.9162e-01,  1.6932e+00, -4.9558e-01, -4.1095e-01,\n",
      "          4.7775e-01,  1.4893e-01, -8.5078e-01,  9.5688e-01,  6.8032e-01,\n",
      "         -3.4780e-01],\n",
      "        [ 1.0991e+00, -5.5103e-01, -1.0776e+00, -1.0900e+00, -5.1874e-02,\n",
      "         -4.3376e-01, -2.9511e-01,  2.8751e-01, -8.6958e-01,  3.9702e-01,\n",
      "         -1.4131e+00,  2.0060e+00, -2.2793e-01,  5.9103e-01,  7.6638e-01,\n",
      "          3.6105e-01, -6.2723e-02, -1.1127e-01,  7.3908e-03, -4.6919e-02,\n",
      "          4.2950e-01,  2.5967e-01,  1.4030e+00, -2.3990e+00, -3.6447e-01,\n",
      "          9.2727e-01],\n",
      "        [ 2.2221e-01,  1.1722e+00, -1.9993e-01, -8.4447e-01,  1.2180e+00,\n",
      "          1.2293e+00, -2.5707e-01, -7.3209e-01, -6.1791e-01,  1.2788e+00,\n",
      "          7.7350e-01,  5.9599e-01, -7.0538e-01, -1.2535e+00, -1.7685e+00,\n",
      "         -7.6791e-01,  3.1055e-01,  9.7549e-01, -9.2734e-01,  7.5757e-01,\n",
      "         -8.4585e-01, -3.1510e-01, -2.3821e+00, -5.7851e-01, -1.2368e-01,\n",
      "         -8.2070e-01],\n",
      "        [ 6.1355e-04,  1.1531e+00, -2.1191e-01,  6.1042e-01, -2.2683e+00,\n",
      "          1.2287e-01, -8.4966e-01, -6.9385e-01, -5.6558e-01,  5.4857e-01,\n",
      "         -1.3140e+00,  5.3668e-01, -9.7104e-01,  1.2816e+00,  5.8127e-01,\n",
      "          4.0927e-01, -1.3828e+00,  5.5430e-01,  5.1123e-01, -3.7409e-01,\n",
      "          6.8011e-01, -1.6021e+00,  1.2462e+00,  1.8270e+00,  1.9557e+00,\n",
      "          3.2311e-01],\n",
      "        [-6.5015e-01, -7.8379e-02, -8.3058e-01,  1.5016e+00,  5.0768e-01,\n",
      "          7.8378e-01,  4.1627e-01, -1.0725e+00,  2.4268e-01, -3.9506e-02,\n",
      "          1.8222e-01, -4.2265e-01, -6.9221e-01,  1.2243e+00,  1.2479e-01,\n",
      "          1.2686e+00,  8.0833e-01,  1.8886e-01, -7.1443e-02,  2.5071e-01,\n",
      "          1.3245e-01, -2.6227e-02, -1.7522e+00, -1.5646e-01,  1.2056e-01,\n",
      "         -1.6764e+00],\n",
      "        [-8.7329e-01, -5.4775e-01,  4.4148e-01, -7.9690e-01,  1.1123e-01,\n",
      "          3.8816e-01,  4.4596e-01, -1.6077e+00,  2.7188e-01,  1.1646e+00,\n",
      "          6.6294e-01, -4.2760e-01, -1.0783e+00,  7.8117e-01,  9.9284e-01,\n",
      "         -1.2195e+00, -9.7182e-01,  4.9764e-01,  5.0592e-01, -3.3183e-01,\n",
      "          2.4564e+00,  1.4024e+00,  5.3615e-01, -1.2817e+00,  1.0894e+00,\n",
      "         -7.8530e-01],\n",
      "        [-9.5758e-01,  5.7766e-01, -5.3464e-01, -1.0171e+00, -2.3413e-01,\n",
      "          9.0540e-01,  3.7979e-01, -6.7841e-02, -3.7263e-01,  6.2918e-01,\n",
      "          4.4518e-01, -4.3306e-01,  1.2591e+00, -6.6865e-02, -3.3279e-01,\n",
      "         -6.1627e-01, -1.6760e-01,  1.2283e+00, -3.1076e-01,  2.9078e-01,\n",
      "          1.3587e+00, -1.3552e+00, -8.7774e-01, -2.3639e+00,  4.8192e-01,\n",
      "         -2.5446e-01],\n",
      "        [-7.4912e-01, -1.7306e+00, -8.2083e-01, -1.5231e-01,  5.8043e-01,\n",
      "          9.4322e-01,  6.1175e-01, -4.2118e-01, -1.7872e+00, -3.8410e-01,\n",
      "         -5.1385e-01, -1.7926e+00,  3.1891e-01, -1.2414e+00, -1.3249e-01,\n",
      "          7.5078e-02,  2.3472e-01, -4.5875e-01,  1.4510e+00,  3.2253e-01,\n",
      "          4.6601e-01,  3.1780e-01,  5.3884e-01,  1.0505e+00,  1.8824e+00,\n",
      "         -7.0316e-01]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(text.lower())\n",
    "\n",
    "unique_words = set(words)\n",
    "print(len(unique_words))\n",
    "print(unique_words)\n",
    "\n",
    "vocab = {word: idx for idx, word in enumerate(unique_words)}\n",
    "print(vocab)\n",
    "\n",
    "sentence_idxs = [vocab[word] for word in word_tokenize(seq_1)]\n",
    "print(len(sentence_idxs))\n",
    "print(sentence_idxs)\n",
    "\n",
    "embedding = nn.Embedding(26, len(unique_words))\n",
    "sentence_vectors = embedding(torch.tensor(sentence_idxs))\n",
    "\n",
    "print(sentence_vectors.shape)\n",
    "print(sentence_vectors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "TXjM7qEUNFY_",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Классификация фамилий по национальности (ConvNet)\n",
    "\n",
    "Датасет: https://disk.yandex.ru/d/owHew8hzPc7X9Q?w=1\n",
    "\n",
    "2.1 Считать файл `surnames/surnames.csv`. \n",
    "\n",
    "2.2 Закодировать национальности числами, начиная с 0.\n",
    "\n",
    "2.3 Разбить датасет на обучающую и тестовую выборку\n",
    "\n",
    "2.4 Реализовать класс `Vocab` (токен = __символ__)\n",
    "  * добавьте в словарь специальный токен `<PAD>` с индексом 0\n",
    "  * при создании словаря сохраните длину самой длинной последовательности из набора данных в виде атрибута `max_seq_len`\n",
    "\n",
    "2.5 Реализовать класс `SurnamesDataset`\n",
    "  * метод `__getitem__` возвращает пару: <последовательность индексов токенов (см. 1.1 ), номер класса> \n",
    "  * длина каждой такой последовательности должна быть одинаковой и равной `vocab.max_seq_len`. Чтобы добиться этого, дополните последовательность справа индексом токена `<PAD>` до нужной длины\n",
    "\n",
    "2.6. Обучить классификатор.\n",
    "  \n",
    "  * Для преобразования последовательности индексов в последовательность векторов используйте `nn.Embedding`. Рассмотрите два варианта: \n",
    "    - когда токен представляется в виде унитарного вектора и модуль `nn.Embedding` не обучается\n",
    "    - когда токен представляется в виде вектора небольшой размерности (меньше, чем размер словаря) и модуль `nn.Embedding` обучается\n",
    "\n",
    "  * Используйте одномерные свертки и пулинг (`nn.Conv1d`, `nn.MaxPool1d`)\n",
    "    - обратите внимание, что `nn.Conv1d` ожидает на вход трехмерный тензор размерности `(batch, embedding_dim, seq_len)`\n",
    "\n",
    "2.7 Измерить точность на тестовой выборке. Проверить работоспособность модели: прогнать несколько фамилий студентов группы через модели и проверить результат. Для каждой фамилии выводить 3 наиболее вероятных предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surname</th>\n",
       "      <th>nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Woodford</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coté</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kore</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Koury</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lebzak</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10975</th>\n",
       "      <td>Quraishi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>Innalls</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>Król</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>Purvis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>Messerli</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10980 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        surname  nationality\n",
       "0      Woodford            0\n",
       "1          Coté            1\n",
       "2          Kore            0\n",
       "3         Koury            2\n",
       "4        Lebzak            3\n",
       "...         ...          ...\n",
       "10975  Quraishi            2\n",
       "10976   Innalls            0\n",
       "10977      Król           12\n",
       "10978    Purvis            0\n",
       "10979  Messerli            9\n",
       "\n",
       "[10980 rows x 2 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surnames = pd.read_csv(\"data/surnames.csv\")\n",
    "surnames['nationality'], _ = pd.factorize(surnames['nationality'])\n",
    "surnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = surnames['surname'].str.lower()\n",
    "y = surnames['nationality']\n",
    "n_classes = y.nunique()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "id": "ZGfJX2NP1sw4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "{0: '<PAD>', 1: 'o', 2: 'q', 3: 's', 4: 'h', 5: 'k', 6: 'b', 7: 'ä', 8: 'ł', 9: 'd', 10: 'ß', 11: 't', 12: 'ó', 13: 'ì', 14: 'g', 15: 'a', 16: 'm', 17: 'è', 18: 'õ', 19: 'ò', 20: 'ń', 21: 'j', 22: 'ú', 23: 'ż', 24: 'ą', 25: \"'\", 26: ':', 27: 'ś', 28: 'l', 29: 'f', 30: 'v', 31: 'ç', 32: '/', 33: 'i', 34: 'ñ', 35: '1', 36: 'y', 37: 'c', 38: 'p', 39: 'u', 40: 'é', 41: 'ü', 42: 'e', 43: 'á', 44: 'r', 45: 'ê', 46: 'w', 47: 'à', 48: 'z', 49: '-', 50: 'n', 51: 'ö', 52: 'x', 53: 'í'}\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "class Vocab:\n",
    "  def __init__(self, data):\n",
    "    tokens = set()\n",
    "    max_seq_len = 0\n",
    "    for item in data:\n",
    "        max_seq_len = max(max_seq_len, len(item))\n",
    "        tokens.update(item)\n",
    "\n",
    "    self.idx_to_token = {0: '<PAD>'}\n",
    "    self.token_to_idx = {'<PAD>': 0}\n",
    "    for idx, token in enumerate(tokens, start=1):\n",
    "        self.idx_to_token[idx] = token\n",
    "        self.token_to_idx[token] = idx\n",
    "    self.vocab_len = len(self.idx_to_token)\n",
    "    self.max_seq_len = max_seq_len\n",
    "\n",
    "vocab = Vocab(X_train)\n",
    "print(vocab.vocab_len)\n",
    "print(vocab.idx_to_token)\n",
    "print(vocab.max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "id": "GHjCRqQg1sw5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SurnamesDataset(Dataset):\n",
    "  def __init__(self, X, y, vocab: Vocab):\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "    self.vocab = vocab\n",
    "\n",
    "  def vectorize(self, surname):\n",
    "    surname_t = torch.zeros(self.vocab.max_seq_len, dtype=torch.int64)\n",
    "    for i, token in enumerate(surname):\n",
    "        if i >= self.vocab.max_seq_len:\n",
    "            break\n",
    "        surname_t[i] = self.vocab.token_to_idx.get(token, 0)\n",
    "    return surname_t\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    surname = self.X.iloc[idx]\n",
    "    label = self.y.iloc[idx]\n",
    "    surname_t = self.vectorize(surname)\n",
    "    return surname_t, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = SurnamesDataset(X_train, y_train, vocab)\n",
    "test_dataset = SurnamesDataset(X_test, y_test, vocab)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([44, 15, 46, 28, 33, 50, 14,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_model(model, train_dataloader, test_dataloader, criterion, optimizer, num_epochs):\n",
    "    model.to(device)\n",
    "    train_losses, test_losses = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss, test_loss = 0, 0\n",
    "        for inputs, labels in train_dataloader:\n",
    "            x = inputs.to(device)\n",
    "            y = labels.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Валидация на val_loader\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        train_losses.append(train_loss/len(train_dataloader))\n",
    "        test_losses.append(test_loss/len(test_dataloader))\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_losses[-1]:.4f}, Test Loss: {test_losses[-1]:.4f}')\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for surnames, labels in dataloader:\n",
    "            x = surnames.to(device)\n",
    "            y = labels.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.5f}')\n",
    "\n",
    "def predict(model, dataset, surname):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        vectorized = dataset.vectorize(surname)\n",
    "        tensor = vectorized.unsqueeze(0).to(device)\n",
    "\n",
    "        logits = model(tensor)\n",
    "\n",
    "        probs = torch.softmax(logits, dim=1).squeeze()\n",
    "        top3_probs, top3_indices = torch.topk(probs, k=3)\n",
    "        print(top3_probs, top3_indices)\n",
    "\n",
    "        top3_nationalities = _[top3_indices.detach().cpu().numpy()]\n",
    "        print(f'{surname}: {top3_nationalities.values[0]} ({top3_probs[0].item():.4f}), {top3_nationalities.values[1]} ({top3_probs[1].item():.4f}), {top3_nationalities.values[2]} ({top3_probs[2].item():.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SurnameClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim, use_unit_vectors=False):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.conv1 = nn.Conv1d(embedding_dim if not use_unit_vectors else vocab_size, 32, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        # print(f\"embedded shape {embedded.shape}\")\n",
    "\n",
    "        conv1_out = self.pool1(torch.relu(self.conv1(embedded)))\n",
    "        # print(f\"conv1 + maxpool shape {conv1_out.shape}\")\n",
    "\n",
    "        conv2_out = self.pool2(torch.relu(self.conv2(conv1_out)))\n",
    "        # print(f\"conv2 + maxpool shape {conv2_out.shape}\")\n",
    "\n",
    "        flattened = self.flatten(conv2_out)\n",
    "        # print(f\"flattened shape {flattened.shape}\")\n",
    "\n",
    "        logits = self.fc(flattened)\n",
    "        # print(f\"fc shape: {logits.shape}\")\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = SurnameClassifier(vocab_size=vocab.vocab_len,\n",
    "                           embedding_dim=vocab.max_seq_len,\n",
    "                           output_dim=len(set(y_train)),\n",
    "                           use_unit_vectors=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество обучаемых параметров: 11112\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Количество обучаемых параметров: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2979, -0.3806, -0.0603,  0.0929, -0.1632, -0.1362, -0.3917, -0.0880,\n",
       "          0.0042, -0.1344,  0.1362, -0.1797,  0.1474, -0.0490, -0.3407,  0.1323,\n",
       "          0.1141, -0.0716]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(train_dataset.vectorize(\"valyaev\").unsqueeze(0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 2.2255, Test Loss: 2.0523\n",
      "Epoch 2, Train Loss: 1.9377, Test Loss: 1.8590\n",
      "Epoch 3, Train Loss: 1.7386, Test Loss: 1.6957\n",
      "Epoch 4, Train Loss: 1.5956, Test Loss: 1.5818\n",
      "Epoch 5, Train Loss: 1.5027, Test Loss: 1.5047\n",
      "Epoch 6, Train Loss: 1.4231, Test Loss: 1.4392\n",
      "Epoch 7, Train Loss: 1.3632, Test Loss: 1.4011\n",
      "Epoch 8, Train Loss: 1.3093, Test Loss: 1.3373\n",
      "Epoch 9, Train Loss: 1.2524, Test Loss: 1.3082\n",
      "Epoch 10, Train Loss: 1.2094, Test Loss: 1.2758\n",
      "Epoch 11, Train Loss: 1.1734, Test Loss: 1.2495\n",
      "Epoch 12, Train Loss: 1.1309, Test Loss: 1.2434\n",
      "Epoch 13, Train Loss: 1.1051, Test Loss: 1.2135\n",
      "Epoch 14, Train Loss: 1.0746, Test Loss: 1.1806\n",
      "Epoch 15, Train Loss: 1.0410, Test Loss: 1.1735\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_dataloader, test_dataloader, criterion, optimizer, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.66530\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.88      0.70       567\n",
      "           1       0.00      0.00      0.00        36\n",
      "           2       0.82      0.99      0.90       346\n",
      "           3       0.82      0.74      0.78       482\n",
      "           4       0.83      0.73      0.78       161\n",
      "           5       0.44      0.89      0.59        36\n",
      "           6       0.37      0.62      0.46       108\n",
      "           7       0.43      0.11      0.18        81\n",
      "           8       0.56      0.12      0.20        41\n",
      "           9       0.42      0.16      0.23       118\n",
      "          10       0.45      0.16      0.23        32\n",
      "          11       0.17      0.02      0.03        57\n",
      "          12       0.00      0.00      0.00        25\n",
      "          13       0.83      0.10      0.18        49\n",
      "          14       0.00      0.00      0.00        15\n",
      "          15       0.50      0.07      0.12        15\n",
      "          16       0.00      0.00      0.00        14\n",
      "          17       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.67      2196\n",
      "   macro avg       0.40      0.31      0.30      2196\n",
      "weighted avg       0.63      0.67      0.62      2196\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True)\n",
    "X_batch, y_batch = next(iter(test_loader))\n",
    "predictions = model(X_batch.to(device)).argmax(dim=1).cpu().detach()\n",
    "print(classification_report(y_batch, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9618, 0.0258, 0.0068]) tensor([3, 7, 0])\n",
      "valyaev: Russian (0.9618), Czech (0.0258), English (0.0068)\n"
     ]
    }
   ],
   "source": [
    "predict(model, train_dataset, 'valyaev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5012, 0.3599, 0.0504]) tensor([3, 0, 8])\n",
      "balinyan: Russian (0.5012), English (0.3599), Irish (0.0504)\n"
     ]
    }
   ],
   "source": [
    "predict(model, train_dataset, 'balinyan')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "uo-hf5CQ0iWv",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Классификация обзоров на фильмы (ConvNet)\n",
    "\n",
    "Датасет: https://disk.yandex.ru/d/tdinpb0nN_Dsrg\n",
    "\n",
    "2.1 Создайте набор данных на основе файлов polarity/positive_reviews.csv (положительные отзывы) и polarity/negative_reviews.csv (отрицательные отзывы). Разбейте на обучающую и тестовую выборку.\n",
    "  * токен = __слово__\n",
    "  * данные для обучения в датасете представляются в виде последовательности индексов токенов\n",
    "  * словарь создается на основе _только_ обучающей выборки. Для корректной обработки ситуаций, когда в тестовой выборке встретится токен, который не хранится в словаре, добавьте в словарь специальный токен `<UNK>`\n",
    "  * добавьте предобработку текста\n",
    "\n",
    "2.2. Обучите классификатор.\n",
    "  \n",
    "  * Для преобразования последовательности индексов в последовательность векторов используйте `nn.Embedding` \n",
    "    - подберите адекватную размерность вектора эмбеддинга: \n",
    "    - модуль `nn.Embedding` обучается\n",
    "\n",
    "  * Используйте одномерные свертки и пулинг (`nn.Conv1d`, `nn.MaxPool1d`)\n",
    "    - обратите внимание, что `nn.Conv1d` ожидает на вход трехмерный тензор размерности `(batch, embedding_dim, seq_len)`\n",
    "\n",
    "\n",
    "2.7 Измерить точность на тестовой выборке. Проверить работоспособность модели: придумать небольшой отзыв, прогнать его через модель и вывести номер предсказанного класса (сделать это для явно позитивного и явно негативного отзыва)\n",
    "* Целевое значение accuracy на валидации - 70+%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"polarity/positive_reviews.txt\") as f:\n",
    "    positive_reviews = sent_tokenize(f.read())\n",
    "\n",
    "with open(\"polarity/negative_reviews.txt\") as f:\n",
    "    negative_reviews = sent_tokenize(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7267, 7091)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_reviews), len(negative_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simplistic , silly and tedious .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it's so laddish and juvenile , only teenage bo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exploitative and largely devoid of the depth o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[garbus] discards the potential for pathologic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a visually flashy but narratively opaque and e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14353</th>\n",
       "      <td>may prove to be [tsai's] masterpiece .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14354</th>\n",
       "      <td>mazel tov to a film about a family's joyous li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14355</th>\n",
       "      <td>standing in the shadows of motown is the best ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14356</th>\n",
       "      <td>it's nice to see piscopo again after all these...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14357</th>\n",
       "      <td>provides a porthole into that noble , tremblin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14358 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  category\n",
       "0                       simplistic , silly and tedious .         1\n",
       "1      it's so laddish and juvenile , only teenage bo...         1\n",
       "2      exploitative and largely devoid of the depth o...         1\n",
       "3      [garbus] discards the potential for pathologic...         1\n",
       "4      a visually flashy but narratively opaque and e...         1\n",
       "...                                                  ...       ...\n",
       "14353             may prove to be [tsai's] masterpiece .         0\n",
       "14354  mazel tov to a film about a family's joyous li...         0\n",
       "14355  standing in the shadows of motown is the best ...         0\n",
       "14356  it's nice to see piscopo again after all these...         0\n",
       "14357  provides a porthole into that noble , tremblin...         0\n",
       "\n",
       "[14358 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = pd.DataFrame()\n",
    "\n",
    "reviews_df[\"text\"] = positive_reviews + negative_reviews\n",
    "reviews_df[\"category\"] = [1 for i in range(len(positive_reviews))] + [0 for i in range(len(negative_reviews))]\n",
    "\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simplistic , silly and tedious .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it s so laddish and juvenile , only teenage bo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exploitative and largely devoid of the depth o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>garbus discard the potential for pathological ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a visually flashy but narratively opaque and e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14353</th>\n",
       "      <td>may prove to be tsai s masterpiece .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14354</th>\n",
       "      <td>mazel tov to a film about a family s joyous li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14355</th>\n",
       "      <td>standing in the shadow of motown is the best k...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14356</th>\n",
       "      <td>it s nice to see piscopo again after all these...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14357</th>\n",
       "      <td>provides a porthole into that noble , tremblin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14358 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  category\n",
       "0                       simplistic , silly and tedious .         1\n",
       "1      it s so laddish and juvenile , only teenage bo...         1\n",
       "2      exploitative and largely devoid of the depth o...         1\n",
       "3      garbus discard the potential for pathological ...         1\n",
       "4      a visually flashy but narratively opaque and e...         1\n",
       "...                                                  ...       ...\n",
       "14353               may prove to be tsai s masterpiece .         0\n",
       "14354  mazel tov to a film about a family s joyous li...         0\n",
       "14355  standing in the shadow of motown is the best k...         0\n",
       "14356  it s nice to see piscopo again after all these...         0\n",
       "14357  provides a porthole into that noble , tremblin...         0\n",
       "\n",
       "[14358 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([' ' if not char.isalpha() and char not in ['.', ',', '!', '?'] else char for char in text])\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    preprocessed_text = ' '.join(lemmatized_tokens)\n",
    "    return preprocessed_text\n",
    "\n",
    "reviews_df[\"text\"] = reviews_df[\"text\"].apply(lambda x: preprocess_text(x))\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it s the perfect kind of film to see when you don t want to use your brain .'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.iloc[9152][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = reviews_df['text'].str.lower()\n",
    "y = reviews_df['category']\n",
    "n_classes = y.nunique()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16510"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Vocab:\n",
    "  def __init__(self, data):\n",
    "    self.idx_to_token = {}\n",
    "    self.token_to_idx = {}\n",
    "    self.vocab_len = 0\n",
    "    self.max_seq_len = 0\n",
    "\n",
    "    for item in data:\n",
    "      self.max_seq_len = max(self.max_seq_len, len(item))\n",
    "\n",
    "    # Добавляем токен для неизвестных слов\n",
    "    self.idx_to_token = {0: '<UNK>'}\n",
    "    self.token_to_idx = {'<UNK>': 0}\n",
    "    self.vocab_len += 1\n",
    "    # Получаем список всех слов в данных\n",
    "    all_words = [word for sentence in data for word in word_tokenize(sentence)]\n",
    "\n",
    "    # Строим словарь\n",
    "    for word in all_words:\n",
    "        if word not in self.token_to_idx:\n",
    "            self.idx_to_token[self.vocab_len] = word\n",
    "            self.token_to_idx[word] = self.vocab_len\n",
    "            self.vocab_len += 1\n",
    "\n",
    "    # Преобразуем данные в последовательности индексов токенов\n",
    "    self.data = []\n",
    "    for sentence in data:\n",
    "        tokens = [self.token_to_idx.get(word, self.token_to_idx['<UNK>']) for word in word_tokenize(sentence)]\n",
    "        self.data.append(tokens)\n",
    "\n",
    "vocab = Vocab(X)\n",
    "vocab.vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "  def __init__(self, X, y, vocab: Vocab):\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "    self.vocab = vocab\n",
    "\n",
    "  def vectorize(self, review):\n",
    "    '''Генерирует представление отзыва review при помощи бинарного кодирования (см. 1.2)'''\n",
    "    vec = torch.zeros(self.vocab.max_seq_len, dtype=torch.int64)\n",
    "\n",
    "\n",
    "    for i, word in enumerate(word_tokenize(review)):\n",
    "\n",
    "      if i >= self.vocab.max_seq_len:\n",
    "        break\n",
    "\n",
    "      vec[i] = self.vocab.token_to_idx.get(word, 0)\n",
    "\n",
    "    return vec\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    vec = self.vectorize(self.X[idx])\n",
    "    label = self.y[idx]\n",
    "    return vec, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = ReviewDataset(X_train, y_train, vocab)\n",
    "test_dataset = ReviewDataset(X_test, y_test, vocab)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ReviewClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, 64, kernel_size=3)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(12928, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        # print(f\"embedded shape: {embedded.shape}\")\n",
    "        # print(self.conv1(embedded).shape)\n",
    "        conv1_out = self.pool(torch.relu(self.conv1(embedded)))\n",
    "        # print(conv1_out.shape)\n",
    "        conv2_out = self.pool(torch.relu(self.conv2(conv1_out)))\n",
    "        # conv3_out = self.pool(torch.relu(self.conv3(conv2_out)))\n",
    "        # print(conv2_out.shape)\n",
    "        flattened = self.flatten(conv2_out)\n",
    "        # print(flattened.shape)\n",
    "        logits = self.fc(flattened)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = ReviewClassifier(vocab_size=vocab.vocab_len,\n",
    "                           embedding_dim=vocab.max_seq_len,\n",
    "                           output_dim=len(set(y_train)))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество обучаемых параметров: 6948552\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Количество обучаемых параметров: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.7138, Test Loss: 0.6933\n",
      "Epoch 2, Train Loss: 0.6935, Test Loss: 0.6927\n",
      "Epoch 3, Train Loss: 0.6929, Test Loss: 0.6942\n",
      "Epoch 4, Train Loss: 0.6920, Test Loss: 0.6946\n",
      "Epoch 5, Train Loss: 0.6837, Test Loss: 0.6775\n",
      "Epoch 6, Train Loss: 0.6272, Test Loss: 0.6564\n",
      "Epoch 7, Train Loss: 0.5291, Test Loss: 0.6726\n",
      "Epoch 8, Train Loss: 0.4253, Test Loss: 0.7524\n",
      "Epoch 9, Train Loss: 0.3460, Test Loss: 0.7354\n",
      "Epoch 10, Train Loss: 0.2837, Test Loss: 0.7961\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_dataloader, test_dataloader, criterion, optimizer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.67061\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rating_labels = [\"Positive\", \"Negative\"]\n",
    "\n",
    "def predict(model, dataset, review):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        vectorized = dataset.vectorize(review)\n",
    "        tensor = vectorized.unsqueeze(0).to(device)\n",
    "        logits = model(tensor)\n",
    "        probs = torch.softmax(logits, dim=1).squeeze()\n",
    "        print(probs)\n",
    "        print(f'{rating_labels[probs.argmax()]} ({probs.max():.4f}), {rating_labels[probs.argmin()]} ({probs.min():.4f}) \\n{review}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.78      0.70      1413\n",
      "           1       0.72      0.57      0.64      1459\n",
      "\n",
      "    accuracy                           0.67      2872\n",
      "   macro avg       0.68      0.67      0.67      2872\n",
      "weighted avg       0.68      0.67      0.67      2872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "model.to(\"cpu\")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True)\n",
    "X_batch, y_batch = next(iter(test_loader))\n",
    "predictions = model(X_batch).argmax(dim=1).cpu().detach()\n",
    "print(classification_report(y_batch, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1447, 0.8553])\n",
      "Negative (0.8553), Positive (0.1447) \n",
      "I had a terrible experience at this restaurant. The staff was rude and the food was overpriced for the quality.\n"
     ]
    }
   ],
   "source": [
    "predict(model, train_dataset, \"I had a terrible experience at this restaurant. The staff was rude and the food was overpriced for the quality.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9951, 0.0049])\n",
      "Positive (0.9951), Negative (0.0049) \n",
      "This restaurant is simply amazing! The food is delicious and the service is outstanding.\n"
     ]
    }
   ],
   "source": [
    "predict(model, train_dataset, \"This restaurant is simply amazing! The food is delicious and the service is outstanding.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5827, 0.4173])\n",
      "Positive (0.5827), Negative (0.4173) \n",
      "The menu at this restaurant is very limited and the food is nothing special. I wouldn't go back.\n"
     ]
    }
   ],
   "source": [
    "predict(model, train_dataset, \"The menu at this restaurant is very limited and the food is nothing special. I wouldn't go back.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9062, 0.0938])\n",
      "Positive (0.9062), Negative (0.0938) \n",
      "I can't say enough good things about this restaurant. It's the perfect place for a romantic dinner or a night out with friends.\n"
     ]
    }
   ],
   "source": [
    "predict(model, train_dataset, \"I can't say enough good things about this restaurant. It's the perfect place for a romantic dinner or a night out with friends.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6659, 0.3341])\n",
      "Positive (0.6659), Negative (0.3341) \n",
      "I had the best dining experience in this restaurant. The ambiance is perfect and the staff is very friendly.\n"
     ]
    }
   ],
   "source": [
    "predict(model, train_dataset, \"I had the best dining experience in this restaurant. The ambiance is perfect and the staff is very friendly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
